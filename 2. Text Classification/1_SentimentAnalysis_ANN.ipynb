{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Clone the GitHub Repository"
      ],
      "metadata": {
        "id": "8RhL9MI5BhTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mehedihasanbijoy/PyTorch-BanglaNLP-Tutorial.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru7_UVAYBgmV",
        "outputId": "d839e3c1-f740-4b1b-aff9-df36bc754428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PyTorch-BanglaNLP-Tutorial'...\n",
            "remote: Enumerating objects: 188, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 188 (delta 5), reused 0 (delta 0), pack-reused 176\u001b[K\n",
            "Receiving objects: 100% (188/188), 3.02 MiB | 16.38 MiB/s, done.\n",
            "Resolving deltas: 100% (94/94), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the dataset"
      ],
      "metadata": {
        "id": "Iu0qqcYhbpQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "\n",
        "df = pd.read_csv('/content/PyTorch-BanglaNLP-Tutorial/0A. Corpus/BanglaEmotion/BanglaEmotion.csv')\n",
        "df = df[['cleaned_text', 'label']]\n",
        "df.dropna(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "do3UK9GS_GjP",
        "outputId": "ece1c075-4bd1-4e19-97d5-bc0c9dc357a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           cleaned_text  label\n",
              "2939  যাই হোক আগে আপনার পক্ষেই ছিলাম যেখানে আপনি অপর...      3\n",
              "3917                 বাংলাদেশ সকল বাঙ্গালির দেশ ধন্যবাদ      3\n",
              "3692  নাহ। আপনার মধ্যে আমি ইসলামের প্রতি শুদ্ধশীলতা ...      4\n",
              "4579                                          ভাল করেছে      3\n",
              "4587                            সব সম্ভবের দেশ বাংলাদেশ      3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-456126ba-8db6-4d7c-b374-eb1b8bc0781a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2939</th>\n",
              "      <td>যাই হোক আগে আপনার পক্ষেই ছিলাম যেখানে আপনি অপর...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3917</th>\n",
              "      <td>বাংলাদেশ সকল বাঙ্গালির দেশ ধন্যবাদ</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3692</th>\n",
              "      <td>নাহ। আপনার মধ্যে আমি ইসলামের প্রতি শুদ্ধশীলতা ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4579</th>\n",
              "      <td>ভাল করেছে</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4587</th>\n",
              "      <td>সব সম্ভবের দেশ বাংলাদেশ</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-456126ba-8db6-4d7c-b374-eb1b8bc0781a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-456126ba-8db6-4d7c-b374-eb1b8bc0781a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-456126ba-8db6-4d7c-b374-eb1b8bc0781a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the dataset into train and test sets"
      ],
      "metadata": {
        "id": "M9iafbulcFiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['cleaned_text'].tolist(),\n",
        "    df['label'].tolist(),\n",
        "    test_size = 0.2,\n",
        "    stratify = df['label'].tolist(),\n",
        "    random_state = 64\n",
        ")"
      ],
      "metadata": {
        "id": "5-UrSWfV_Gl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_len(X):\n",
        "    return len(X.split())\n",
        "\n",
        "def sort_by_length(X, y):\n",
        "    df = pd.DataFrame({'X': X, 'y': y})\n",
        "    df['len'] = df['X'].apply(find_len)\n",
        "    df = df.sort_values(by='len', ascending=True)\n",
        "    return list(df['X']), list(df['y'])"
      ],
      "metadata": {
        "id": "xWiMPiH8I3uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = sort_by_length(X_train, y_train)\n",
        "X_test, y_test = sort_by_length(X_test, y_test)"
      ],
      "metadata": {
        "id": "5NdtQgDxJ0BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# print the statistics of train and test sets\n",
        "print(f'Train data instances: {len(X_train)}\\nClass distribution: {Counter(y_train)}')\n",
        "print(f'\\nTest data instances: {len(X_test)}\\nClass distribution: {Counter(y_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D72QAyxs_Gri",
        "outputId": "9a6ffd9f-0a31-4bb1-97f6-668c1ea73c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data instances: 4511\n",
            "Class distribution: Counter({3: 1440, 0: 960, 4: 959, 1: 480, 5: 384, 2: 288})\n",
            "\n",
            "Test data instances: 1128\n",
            "Class distribution: Counter({3: 360, 4: 240, 0: 240, 1: 120, 5: 96, 2: 72})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# create iterator: list of tuples -> (label, text)\n",
        "train_data = list(zip(y_train, X_train))\n",
        "test_data = list(zip(y_test, X_test))\n",
        "\n",
        "# display training samples\n",
        "random.choices(train_data, k = 5)"
      ],
      "metadata": {
        "id": "MdH7kO5Q_Gup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e28e71-5a87-4346-b3b3-91236704aeb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(4,\n",
              "  'অনেক দিন পর আপনার লেখা ভালো ভাবে নিতে পারিনি। একজন ভালো মানুষের জন্য লিখলে ভালো হত।'),\n",
              " (1, 'তোমাকে কত বার তারা ব্যাবহার করেছে তা আমরা ঠিক ই বুজে গেছি,'),\n",
              " (3,\n",
              "  'ইমরান এইচ সরকার এর ঊন্নতি হইছে দেখতাছি।যাক দেরিতে হলেও বোধোদয় হইছে ।সরকারের দালালি থেকে সরে এসে হক কথা বলার জন্য থেংকু।'),\n",
              " (4, 'নিশেদাজ্ঞা তো ভাল ছিল জাত্রি হয়রানি আবার বারবে,'),\n",
              " (5,\n",
              "  'আপনার মতে কি দেশের সব ম্যাজিস্ট্রেট সাধু? খবর নিয়ে দেখেন তারা টাকাকড়ি খায় কিনা')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "cGEOOiZ8dtC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "hgynYso-pyko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchtext.data.utils import get_tokenizer\n",
        "# tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def tokenizer(x):\n",
        "    return x.lower().split()\n",
        "\n",
        "def yield_tokens(data_iterator):\n",
        "    for _, text in data_iterator:\n",
        "        yield tokenizer(text)"
      ],
      "metadata": {
        "id": "Mrolb0w9pysN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# build vocabulary\n",
        "VOCAB = build_vocab_from_iterator(yield_tokens(train_data), specials=[''])\n",
        "VOCAB.set_default_index(VOCAB[''])"
      ],
      "metadata": {
        "id": "g-eK3rMapyue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create pipelines\n",
        "TEXT_PIPELINE = lambda x: VOCAB(tokenizer(x))\n",
        "LABEL_PIPELINE = lambda x: int(x)\n",
        "\n",
        "# pipelines in action\n",
        "print(TEXT_PIPELINE('একজন ভালো মানুষের জন্য লিখলে ভালো হত।'))\n",
        "print(LABEL_PIPELINE('2'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaSigbTwpyw5",
        "outputId": "49951631-93e8-444d-c0e6-226dcbe55e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[92, 67, 94, 9, 3604, 67, 1513]\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch collate function\n",
        "def collate_batch(batch):\n",
        "    labels, texts, offsets = [], [], [0]\n",
        "    for (label, text) in batch:\n",
        "        labels.append(LABEL_PIPELINE(label))\n",
        "        _texts = torch.tensor(TEXT_PIPELINE(text), dtype=torch.int64)\n",
        "        texts.append(_texts)\n",
        "        offsets.append(_texts.size(0))\n",
        "    labels = torch.tensor(labels, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    texts = torch.cat(texts)\n",
        "    return labels.to(DEVICE), texts.to(DEVICE), offsets.to(DEVICE)"
      ],
      "metadata": {
        "id": "51UQRV4CpyzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# hyperparameters\n",
        "EPOCHS = 25\n",
        "LEARNING_RATE = 0.5\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# dataloaders\n",
        "train_loader = DataLoader(train_data, batch_size = BATCH_SIZE, shuffle = True, collate_fn = collate_batch)  # train data is train iterator\n",
        "test_loader = DataLoader(test_data, batch_size = BATCH_SIZE, shuffle = True, collate_fn = collate_batch)  # test data is test iterator"
      ],
      "metadata": {
        "id": "_xL7T7EhK0UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Classification Model\n",
        "A feed-forward neural network"
      ],
      "metadata": {
        "id": "rc6nHzIghCG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FeedForwardNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(FeedForwardNN, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc1 = nn.Linear(embed_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 16)\n",
        "        self.fc4 = nn.Linear(16, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.68\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc1.bias.data.zero_()\n",
        "        self.fc2.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc2.bias.data.zero_()\n",
        "        self.fc3.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc3.bias.data.zero_()\n",
        "        self.fc4.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc4.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        x = F.relu(self.fc1(embedded))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vilqyyt3Er8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = len(set([label for (label, text) in train_data]))\n",
        "VOCAB_SIZE = len(VOCAB)\n",
        "EMBED_SIZE = 128\n",
        "\n",
        "# initialize the model\n",
        "model = FeedForwardNN(VOCAB_SIZE, EMBED_SIZE, NUM_CLASSES).to(DEVICE)"
      ],
      "metadata": {
        "id": "hZRjvxWvYBuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss fn, optimizer, scheduler\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)"
      ],
      "metadata": {
        "id": "-Hb5X0byYN3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Evaluate the Model"
      ],
      "metadata": {
        "id": "RklO8aP0hzCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 100\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predited_label = model(text, offsets)\n",
        "        loss = criterion(predited_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc/total_count))\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()"
      ],
      "metadata": {
        "id": "cRyXVh0nrwc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predited_label = model(text, offsets)\n",
        "            loss = criterion(predited_label, label)\n",
        "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count"
      ],
      "metadata": {
        "id": "NfjCON_Lrwfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_accu = None\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_loader)\n",
        "    accu_val = evaluate(test_loader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'test accuracy {:8.3f} '.format(epoch, time.time() - epoch_start_time, accu_val))\n",
        "    print('-' * 59)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOVLKVn8XLEI",
        "outputId": "6b03af63-43b3-4065-b0bf-c01572a009c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time:  0.62s | test accuracy    0.275 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time:  0.46s | test accuracy    0.298 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time:  0.40s | test accuracy    0.317 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time:  0.41s | test accuracy    0.313 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time:  0.40s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time:  0.45s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time:  0.40s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time:  0.40s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time:  0.41s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time:  0.39s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  11 | time:  0.40s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  12 | time:  0.42s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  13 | time:  0.41s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  14 | time:  0.41s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  15 | time:  0.42s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  16 | time:  0.40s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  17 | time:  0.41s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  18 | time:  0.39s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  19 | time:  0.42s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  20 | time:  0.43s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  21 | time:  0.42s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  22 | time:  0.40s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  23 | time:  0.40s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  24 | time:  0.42s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  25 | time:  0.42s | test accuracy    0.316 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the Model on Input Text"
      ],
      "metadata": {
        "id": "chccJbgAl49E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_label = {0: \"Angry\", 1: \"Disgust\", 2: \"Fear\", 3: \"Happy\", 4: \"Sad\", 5: \"Surprise\"}\n",
        "\n",
        "def predict(text, text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() "
      ],
      "metadata": {
        "id": "Z5qYVJrSl4h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_text = \"অত্যন্ত মর্মাহত হলাম। \"\n",
        "\n",
        "print(f\"This is a {sentiment_label[predict(inp_text, TEXT_PIPELINE)]} tweet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEkkWcVBmdWs",
        "outputId": "63236df2-ae78-46d6-907c-67548cc704bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a Angry tweet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References"
      ],
      "metadata": {
        "id": "4Sym3IOoifDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html"
      ],
      "metadata": {
        "id": "tiVI6aPu_G9y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}