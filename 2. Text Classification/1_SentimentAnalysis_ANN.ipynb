{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Clone the GitHub Repository"
      ],
      "metadata": {
        "id": "8RhL9MI5BhTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mehedihasanbijoy/PyTorch-NLP-Tutorial.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru7_UVAYBgmV",
        "outputId": "00769c07-ca93-4970-f02e-51f379b90f2d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'PyTorch-NLP-Tutorial' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the dataset"
      ],
      "metadata": {
        "id": "Iu0qqcYhbpQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "\n",
        "df = pd.read_csv('/content/PyTorch-NLP-Tutorial/1. Text Classification/corpus/TweetSentiment.csv')\n",
        "df = df[['preprocessed_text', 'label']]\n",
        "df.dropna(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "do3UK9GS_GjP",
        "outputId": "a63019c9-91e8-4e02-8f71-c7073f3283df"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       preprocessed_text  label\n",
              "23080              happy mother day to all mom out there      2\n",
              "7837   ehi might drive through chitown on my way to c...      1\n",
              "25464                      awake sadly seeing leon today      0\n",
              "29699  good morning been here since am just quiet how...      2\n",
              "15838  game who want itu already know who the league ...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-892ec19a-3d33-42e6-b2eb-4ed863e08d73\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preprocessed_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23080</th>\n",
              "      <td>happy mother day to all mom out there</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7837</th>\n",
              "      <td>ehi might drive through chitown on my way to c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25464</th>\n",
              "      <td>awake sadly seeing leon today</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29699</th>\n",
              "      <td>good morning been here since am just quiet how...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15838</th>\n",
              "      <td>game who want itu already know who the league ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-892ec19a-3d33-42e6-b2eb-4ed863e08d73')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-892ec19a-3d33-42e6-b2eb-4ed863e08d73 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-892ec19a-3d33-42e6-b2eb-4ed863e08d73');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the dataset into train and test sets"
      ],
      "metadata": {
        "id": "M9iafbulcFiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['preprocessed_text'].tolist(),\n",
        "    df['label'].tolist(),\n",
        "    test_size = 0.2,\n",
        "    stratify = df['label'].tolist(),\n",
        "    random_state = 64\n",
        ")"
      ],
      "metadata": {
        "id": "5-UrSWfV_Gl2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_len(X):\n",
        "    return len(X.split())\n",
        "\n",
        "def sort_by_length(X, y):\n",
        "    df = pd.DataFrame({'X': X, 'y': y})\n",
        "    df['len'] = df['X'].apply(find_len)\n",
        "    df = df.sort_values(by='len', ascending=True)\n",
        "    return list(df['X']), list(df['y'])"
      ],
      "metadata": {
        "id": "xWiMPiH8I3uV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = sort_by_length(X_train, y_train)\n",
        "X_test, y_test = sort_by_length(X_test, y_test)"
      ],
      "metadata": {
        "id": "5NdtQgDxJ0BQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# print the statistics of train and test sets\n",
        "print(f'Train data instances: {len(X_train)}\\nClass distribution: {Counter(y_train)}')\n",
        "print(f'\\nTest data instances: {len(X_test)}\\nClass distribution: {Counter(y_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D72QAyxs_Gri",
        "outputId": "abc3d16e-3b1b-4269-878a-7e22f7f72a27"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data instances: 24808\n",
            "Class distribution: Counter({1: 10035, 2: 7748, 0: 7025})\n",
            "\n",
            "Test data instances: 6202\n",
            "Class distribution: Counter({1: 2509, 2: 1937, 0: 1756})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# create iterator: list of tuples -> (label, text)\n",
        "train_data = list(zip(y_train, X_train))\n",
        "test_data = list(zip(y_test, X_test))\n",
        "\n",
        "# display training samples\n",
        "random.choices(train_data, k = 5)"
      ],
      "metadata": {
        "id": "MdH7kO5Q_Gup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a00d0492-947c-446a-e911-9e5456fec119"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  'darn it im craving wedding cake a craving thats very hard to satisfy with anything else'),\n",
              " (1, 'tonight is the last jay leno late nigt show'),\n",
              " (0,\n",
              "  'drat all my land boot died at once i think of boot like parsley one going to seed the other first season what to do now'),\n",
              " (1, 'bandoni ok see you at da climbing'),\n",
              " (0, 'i wa scared by the daleks in the dw exhibition in cardiff')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "cGEOOiZ8dtC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "hgynYso-pyko"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchtext.data.utils import get_tokenizer\n",
        "# tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def tokenizer(x):\n",
        "    return x.lower().split()\n",
        "\n",
        "def yield_tokens(data_iterator):\n",
        "    for _, text in data_iterator:\n",
        "        yield tokenizer(text)"
      ],
      "metadata": {
        "id": "Mrolb0w9pysN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# build vocabulary\n",
        "VOCAB = build_vocab_from_iterator(yield_tokens(train_data), specials=[''])\n",
        "VOCAB.set_default_index(VOCAB[''])"
      ],
      "metadata": {
        "id": "g-eK3rMapyue"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create pipelines\n",
        "TEXT_PIPELINE = lambda x: VOCAB(tokenizer(x))\n",
        "LABEL_PIPELINE = lambda x: int(x)\n",
        "\n",
        "# pipelines in action\n",
        "print(TEXT_PIPELINE('This is an example'))\n",
        "print(LABEL_PIPELINE('2'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaSigbTwpyw5",
        "outputId": "f23405a0-c058-4024-f20a-9b21d1c68d21"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[29, 9, 87, 5001]\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch collate function\n",
        "def collate_batch(batch):\n",
        "    labels, texts, offsets = [], [], [0]\n",
        "    for (label, text) in batch:\n",
        "        labels.append(LABEL_PIPELINE(label))\n",
        "        _texts = torch.tensor(TEXT_PIPELINE(text), dtype=torch.int64)\n",
        "        texts.append(_texts)\n",
        "        offsets.append(_texts.size(0))\n",
        "    labels = torch.tensor(labels, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    texts = torch.cat(texts)\n",
        "    return labels.to(DEVICE), texts.to(DEVICE), offsets.to(DEVICE)"
      ],
      "metadata": {
        "id": "51UQRV4CpyzV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# hyperparameters\n",
        "EPOCHS = 25\n",
        "LEARNING_RATE = 0.5\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# dataloaders\n",
        "train_loader = DataLoader(train_data, batch_size = BATCH_SIZE, shuffle = True, collate_fn = collate_batch)  # train data is train iterator\n",
        "test_loader = DataLoader(test_data, batch_size = BATCH_SIZE, shuffle = True, collate_fn = collate_batch)  # test data is test iterator"
      ],
      "metadata": {
        "id": "_xL7T7EhK0UB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Classification Model\n",
        "A feed-forward neural network"
      ],
      "metadata": {
        "id": "rc6nHzIghCG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FeedForwardNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(FeedForwardNN, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc1 = nn.Linear(embed_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 16)\n",
        "        self.fc4 = nn.Linear(16, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.68\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc1.bias.data.zero_()\n",
        "        self.fc2.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc2.bias.data.zero_()\n",
        "        self.fc3.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc3.bias.data.zero_()\n",
        "        self.fc4.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc4.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        x = F.relu(self.fc1(embedded))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vilqyyt3Er8a"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = len(set([label for (label, text) in train_data]))\n",
        "VOCAB_SIZE = len(VOCAB)\n",
        "EMBED_SIZE = 128\n",
        "\n",
        "# initialize the model\n",
        "model = FeedForwardNN(VOCAB_SIZE, EMBED_SIZE, NUM_CLASSES).to(DEVICE)"
      ],
      "metadata": {
        "id": "hZRjvxWvYBuX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss fn, optimizer, scheduler\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)"
      ],
      "metadata": {
        "id": "-Hb5X0byYN3O"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Evaluate the Model"
      ],
      "metadata": {
        "id": "RklO8aP0hzCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 100\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predited_label = model(text, offsets)\n",
        "        loss = criterion(predited_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc/total_count))\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()"
      ],
      "metadata": {
        "id": "cRyXVh0nrwc9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predited_label = model(text, offsets)\n",
        "            loss = criterion(predited_label, label)\n",
        "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count"
      ],
      "metadata": {
        "id": "NfjCON_Lrwfg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_accu = None\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_loader)\n",
        "    accu_val = evaluate(test_loader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'test accuracy {:8.3f} '.format(epoch, time.time() - epoch_start_time, accu_val))\n",
        "    print('-' * 59)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOVLKVn8XLEI",
        "outputId": "edf2143c-60d5-4ed4-dd09-0d9ab16e94ae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   100/  388 batches | accuracy    0.359\n",
            "| epoch   1 |   200/  388 batches | accuracy    0.370\n",
            "| epoch   1 |   300/  388 batches | accuracy    0.391\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time:  2.26s | test accuracy    0.424 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   100/  388 batches | accuracy    0.414\n",
            "| epoch   2 |   200/  388 batches | accuracy    0.428\n",
            "| epoch   2 |   300/  388 batches | accuracy    0.426\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time:  3.86s | test accuracy    0.454 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   100/  388 batches | accuracy    0.438\n",
            "| epoch   3 |   200/  388 batches | accuracy    0.444\n",
            "| epoch   3 |   300/  388 batches | accuracy    0.465\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time:  3.96s | test accuracy    0.471 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   100/  388 batches | accuracy    0.463\n",
            "| epoch   4 |   200/  388 batches | accuracy    0.471\n",
            "| epoch   4 |   300/  388 batches | accuracy    0.475\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time:  5.23s | test accuracy    0.496 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   100/  388 batches | accuracy    0.490\n",
            "| epoch   5 |   200/  388 batches | accuracy    0.504\n",
            "| epoch   5 |   300/  388 batches | accuracy    0.494\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time:  4.40s | test accuracy    0.502 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   100/  388 batches | accuracy    0.514\n",
            "| epoch   6 |   200/  388 batches | accuracy    0.515\n",
            "| epoch   6 |   300/  388 batches | accuracy    0.521\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time:  2.05s | test accuracy    0.520 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   100/  388 batches | accuracy    0.530\n",
            "| epoch   7 |   200/  388 batches | accuracy    0.526\n",
            "| epoch   7 |   300/  388 batches | accuracy    0.526\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time:  2.00s | test accuracy    0.534 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   100/  388 batches | accuracy    0.543\n",
            "| epoch   8 |   200/  388 batches | accuracy    0.547\n",
            "| epoch   8 |   300/  388 batches | accuracy    0.548\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time:  2.02s | test accuracy    0.545 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   100/  388 batches | accuracy    0.570\n",
            "| epoch   9 |   200/  388 batches | accuracy    0.556\n",
            "| epoch   9 |   300/  388 batches | accuracy    0.545\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time:  2.07s | test accuracy    0.552 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   100/  388 batches | accuracy    0.568\n",
            "| epoch  10 |   200/  388 batches | accuracy    0.573\n",
            "| epoch  10 |   300/  388 batches | accuracy    0.561\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time:  2.13s | test accuracy    0.558 \n",
            "-----------------------------------------------------------\n",
            "| epoch  11 |   100/  388 batches | accuracy    0.586\n",
            "| epoch  11 |   200/  388 batches | accuracy    0.582\n",
            "| epoch  11 |   300/  388 batches | accuracy    0.577\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  11 | time:  2.10s | test accuracy    0.566 \n",
            "-----------------------------------------------------------\n",
            "| epoch  12 |   100/  388 batches | accuracy    0.596\n",
            "| epoch  12 |   200/  388 batches | accuracy    0.585\n",
            "| epoch  12 |   300/  388 batches | accuracy    0.597\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  12 | time:  1.94s | test accuracy    0.569 \n",
            "-----------------------------------------------------------\n",
            "| epoch  13 |   100/  388 batches | accuracy    0.611\n",
            "| epoch  13 |   200/  388 batches | accuracy    0.592\n",
            "| epoch  13 |   300/  388 batches | accuracy    0.595\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  13 | time:  2.22s | test accuracy    0.574 \n",
            "-----------------------------------------------------------\n",
            "| epoch  14 |   100/  388 batches | accuracy    0.627\n",
            "| epoch  14 |   200/  388 batches | accuracy    0.602\n",
            "| epoch  14 |   300/  388 batches | accuracy    0.590\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  14 | time:  2.13s | test accuracy    0.579 \n",
            "-----------------------------------------------------------\n",
            "| epoch  15 |   100/  388 batches | accuracy    0.629\n",
            "| epoch  15 |   200/  388 batches | accuracy    0.623\n",
            "| epoch  15 |   300/  388 batches | accuracy    0.619\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  15 | time:  2.17s | test accuracy    0.588 \n",
            "-----------------------------------------------------------\n",
            "| epoch  16 |   100/  388 batches | accuracy    0.621\n",
            "| epoch  16 |   200/  388 batches | accuracy    0.624\n",
            "| epoch  16 |   300/  388 batches | accuracy    0.628\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  16 | time:  2.09s | test accuracy    0.584 \n",
            "-----------------------------------------------------------\n",
            "| epoch  17 |   100/  388 batches | accuracy    0.639\n",
            "| epoch  17 |   200/  388 batches | accuracy    0.643\n",
            "| epoch  17 |   300/  388 batches | accuracy    0.640\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  17 | time:  2.09s | test accuracy    0.587 \n",
            "-----------------------------------------------------------\n",
            "| epoch  18 |   100/  388 batches | accuracy    0.636\n",
            "| epoch  18 |   200/  388 batches | accuracy    0.651\n",
            "| epoch  18 |   300/  388 batches | accuracy    0.637\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  18 | time:  2.19s | test accuracy    0.587 \n",
            "-----------------------------------------------------------\n",
            "| epoch  19 |   100/  388 batches | accuracy    0.642\n",
            "| epoch  19 |   200/  388 batches | accuracy    0.646\n",
            "| epoch  19 |   300/  388 batches | accuracy    0.633\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  19 | time:  2.23s | test accuracy    0.587 \n",
            "-----------------------------------------------------------\n",
            "| epoch  20 |   100/  388 batches | accuracy    0.637\n",
            "| epoch  20 |   200/  388 batches | accuracy    0.638\n",
            "| epoch  20 |   300/  388 batches | accuracy    0.638\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  20 | time:  2.16s | test accuracy    0.587 \n",
            "-----------------------------------------------------------\n",
            "| epoch  21 |   100/  388 batches | accuracy    0.646\n",
            "| epoch  21 |   200/  388 batches | accuracy    0.643\n",
            "| epoch  21 |   300/  388 batches | accuracy    0.628\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  21 | time:  2.14s | test accuracy    0.587 \n",
            "-----------------------------------------------------------\n",
            "| epoch  22 |   100/  388 batches | accuracy    0.627\n",
            "| epoch  22 |   200/  388 batches | accuracy    0.638\n",
            "| epoch  22 |   300/  388 batches | accuracy    0.652\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  22 | time:  2.13s | test accuracy    0.587 \n",
            "-----------------------------------------------------------\n",
            "| epoch  23 |   100/  388 batches | accuracy    0.636\n",
            "| epoch  23 |   200/  388 batches | accuracy    0.643\n",
            "| epoch  23 |   300/  388 batches | accuracy    0.642\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  23 | time:  2.08s | test accuracy    0.587 \n",
            "-----------------------------------------------------------\n",
            "| epoch  24 |   100/  388 batches | accuracy    0.638\n",
            "| epoch  24 |   200/  388 batches | accuracy    0.641\n",
            "| epoch  24 |   300/  388 batches | accuracy    0.637\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  24 | time:  2.37s | test accuracy    0.587 \n",
            "-----------------------------------------------------------\n",
            "| epoch  25 |   100/  388 batches | accuracy    0.643\n",
            "| epoch  25 |   200/  388 batches | accuracy    0.647\n",
            "| epoch  25 |   300/  388 batches | accuracy    0.636\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  25 | time:  3.11s | test accuracy    0.587 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the Model on Input Text"
      ],
      "metadata": {
        "id": "chccJbgAl49E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_label = {2: \"Positive\", 0: \"Negative\", 1: \"Neutral\"}\n",
        "\n",
        "def predict(text, text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() "
      ],
      "metadata": {
        "id": "Z5qYVJrSl4h1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inp_text = \"Soooooo wish I could, but im in school and myspace is completely blocked\"\n",
        "# inp_text = \"The product is not good\"\n",
        "inp_text = \"It's super fun\"\n",
        "\n",
        "print(f\"This is a {sentiment_label[predict(inp_text, TEXT_PIPELINE)]} tweet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEkkWcVBmdWs",
        "outputId": "485713f7-b07c-487a-d285-9b9ff80e1585"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a Positive tweet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References"
      ],
      "metadata": {
        "id": "4Sym3IOoifDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html"
      ],
      "metadata": {
        "id": "tiVI6aPu_G9y"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}