{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install text-preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M4w_UW0tW0r",
        "outputId": "1b7bf62b-731b-4d27-b371-a38450a490e8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting text-preprocessing\n",
            "  Downloading text_preprocessing-0.1.1-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting unittest-xml-reporting\n",
            "  Downloading unittest_xml_reporting-3.2.0-py2.py3-none-any.whl (20 kB)\n",
            "Collecting names-dataset==2.1\n",
            "  Downloading names_dataset-2.1.0-py3-none-any.whl (62.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 62.6 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.7.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 60.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from text-preprocessing) (3.7)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (110 kB)\n",
            "\u001b[K     |████████████████████████████████| 110 kB 70.9 MB/s \n",
            "\u001b[?25hCollecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 70.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->text-preprocessing) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->text-preprocessing) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk->text-preprocessing) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->text-preprocessing) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from unittest-xml-reporting->text-preprocessing) (4.9.2)\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, unittest-xml-reporting, pyspellchecker, names-dataset, contractions, text-preprocessing\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.73 names-dataset-2.1.0 pyahocorasick-1.4.4 pyspellchecker-0.7.1 text-preprocessing-0.1.1 textsearch-0.0.24 unittest-xml-reporting-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from text_preprocessing import preprocess_text\n",
        "from text_preprocessing import to_lower, remove_email, remove_url, remove_punctuation\n",
        "\n",
        "preprocess_functions = [to_lower, remove_email, remove_url, remove_punctuation]\n",
        "\n",
        "def clean_text(text):\n",
        "    return preprocess_text(text, preprocess_functions)"
      ],
      "metadata": {
        "id": "EdoKVSFItYiT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26beb157-bd62-49c1-9a55-f2c9e29edc7a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment2label(sentiment):\n",
        "    return 0 if sentiment == 'negative' else 1"
      ],
      "metadata": {
        "id": "BGDzjCZGtXmr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/PyTorch/PyTorch-NLP-Tutorial/Corpus/IMDB Dataset.csv')\n",
        "df['text'] = df['review'].apply(clean_text)\n",
        "df['label'] = df['sentiment'].apply(sentiment2label)\n",
        "df = df[['text', 'label']]\n",
        "df.dropna(inplace=True) \n",
        "df.reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "gezKwpMZtXuF",
        "outputId": "2ba356c0-9b9e-4049-98ee-6bc7f22a7923"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  label\n",
              "0      one of the other reviewers has mentioned that ...      1\n",
              "1      a wonderful little production br br the filmin...      1\n",
              "2      i thought this was a wonderful way to spend ti...      1\n",
              "3      basically theres a family where a little boy j...      0\n",
              "4      petter matteis love in the time of money is a ...      1\n",
              "...                                                  ...    ...\n",
              "49995  i thought this movie did a down right good job...      1\n",
              "49996  bad plot bad dialogue bad acting idiotic direc...      0\n",
              "49997  i am a catholic taught in parochial elementary...      0\n",
              "49998  im going to have to disagree with the previous...      0\n",
              "49999  no one expects the star trek movies to be high...      0\n",
              "\n",
              "[50000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6948ad3-1f7d-41b7-8817-bdb5478ced81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a wonderful little production br br the filmin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically theres a family where a little boy j...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter matteis love in the time of money is a ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>i thought this movie did a down right good job...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>i am a catholic taught in parochial elementary...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>im going to have to disagree with the previous...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>no one expects the star trek movies to be high...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6948ad3-1f7d-41b7-8817-bdb5478ced81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6948ad3-1f7d-41b7-8817-bdb5478ced81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6948ad3-1f7d-41b7-8817-bdb5478ced81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary: \n",
        "    def __init__(self, freq_threshold=10, max_size=100000):\n",
        "        '''\n",
        "        freq_threshold : the minimum times a word must occur in corpus to be included in vocabulary\n",
        "        max_size : max vocab size\n",
        "        '''\n",
        "        self.freq_threshold = freq_threshold\n",
        "        self.max_size = max_size\n",
        "\n",
        "        self.itos = {0: '<PAD>', 1:'<SOS>', 2:'<EOS>', 3: '<UNK>'}\n",
        "        self.stoi = {k:j for j, k in self.itos.items()} \n",
        "          \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "    \n",
        "\n",
        "    @staticmethod\n",
        "    def tokenizer(text):\n",
        "        return [tok.lower().strip() for tok in text.split(' ')]\n",
        "\n",
        "    \n",
        "    @staticmethod\n",
        "    def generate_bigrams(x):\n",
        "        n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
        "        for n_gram in n_grams:\n",
        "            x.append(' '.join(n_gram))\n",
        "        return x\n",
        "\n",
        "    \n",
        "    def build_vocabulary(self, sentence_list):\n",
        "        '''\n",
        "        build the vocabulary: create a dictionary mapping of index to string (itos) and string to index (stoi)\n",
        "        (itos) -> {5:'the', 6:'a', 7:'an'} | (stoi) -> {'the':5, 'a':6, 'an':7}\n",
        "        '''\n",
        "        frequencies = {} \n",
        "        idx = 4  # because 4 tokens already added -> (itos) -> {0: '<PAD>', 1:'<SOS>', 2:'<EOS>', 3: '<UNK>'}\n",
        "        \n",
        "        # # calculate the freq of words\n",
        "        # for sentence in sentence_list:\n",
        "        #     for word in self.tokenizer(sentence):\n",
        "        #         if word not in frequencies.keys():\n",
        "        #             frequencies[word] = 1\n",
        "        #         else:\n",
        "        #             frequencies[word] += 1\n",
        "        \n",
        "\n",
        "        # calculate the freq of words\n",
        "        for sentence in sentence_list:\n",
        "\n",
        "            sentence = self.tokenizer(sentence)\n",
        "            sentence_n_bigrams = self.generate_bigrams(sentence)\n",
        "\n",
        "            for word in sentence_n_bigrams:\n",
        "                if word not in frequencies.keys():\n",
        "                    frequencies[word] = 1\n",
        "                else:\n",
        "                    frequencies[word] += 1\n",
        "                    \n",
        "                    \n",
        "        # limit vocab by removing low freq words\n",
        "        frequencies = {k:v for k,v in frequencies.items() if v >= self.freq_threshold} \n",
        "        \n",
        "        # limit vocab to the max_size specified\n",
        "        frequencies = dict(sorted(frequencies.items(), key = lambda x: -x[1])[:self.max_size-idx]) # idx = 4 for pad, start, end , unk\n",
        "            \n",
        "        # create vocab\n",
        "        for word in frequencies.keys():\n",
        "            self.stoi[word] = idx\n",
        "            self.itos[idx] = word\n",
        "            idx += 1\n",
        "\n",
        " \n",
        "    # def numericalize(self, text):\n",
        "    #     '''\n",
        "    #     convert the list of words to a list of corresponding indexes\n",
        "    #     eg. cat and a dog -> [4, 5, 6, 3]\n",
        "    #     '''   \n",
        "    #     tokenized_text = self.tokenizer(text)  # tokenize text \n",
        "    #     numericalized_text = []\n",
        "\n",
        "    #     for token in tokenized_text:\n",
        "    #         if token in self.stoi.keys():\n",
        "    #             numericalized_text.append(self.stoi[token])\n",
        "    #         else: # out-of-vocab (OOV) words are represented by UNK token index\n",
        "    #             numericalized_text.append(self.stoi['<UNK>'])\n",
        "                \n",
        "    #     return numericalized_text\n",
        "\n",
        "    def numericalize(self, text):\n",
        "        tokenized_text = self.tokenizer(text)  # tokenize text \n",
        "        sentence_n_bigrams = self.generate_bigrams(tokenized_text)\n",
        "\n",
        "        numericalized_text = []\n",
        "\n",
        "        for token in sentence_n_bigrams:\n",
        "            if token in self.stoi.keys():\n",
        "                numericalized_text.append(self.stoi[token])\n",
        "            else: # out-of-vocab (OOV) words are represented by UNK token index\n",
        "                numericalized_text.append(self.stoi['<UNK>'])\n",
        "                \n",
        "        return numericalized_text"
      ],
      "metadata": {
        "id": "_nH53zlbtX1k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab = Vocabulary(1, 100)\n",
        "# vocab.build_vocabulary(\n",
        "#     ['Joe waited for the train', 'The train was late', 'This is a cat', 'Dogs are friendly']\n",
        "# )\n",
        "\n",
        "# print(vocab.numericalize('The train was late'))\n",
        "# print(vocab.stoi)"
      ],
      "metadata": {
        "id": "mTVrqkKdEQqy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "metadata": {
        "id": "wPwxAk9jxx_m"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df, text_column, label_column, freq_threshold=5, vocab_size=10000):\n",
        "        self.df = df\n",
        "        \n",
        "        # get texts and labels\n",
        "        self.texts = self.df[text_column]\n",
        "        self.labels = self.df[label_column]\n",
        "        \n",
        "        # build vocabulary\n",
        "        self.vocab = Vocabulary(freq_threshold, vocab_size)\n",
        "        self.vocab.build_vocabulary(self.texts.tolist())\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        text = self.texts[int(index)]\n",
        "        label = self.labels[index]\n",
        "            \n",
        "        # numericalize texts ['<SOS>','cat', 'in', 'a', 'bag','<EOS>'] -> [1,12,2,9,24,2]\n",
        "        numerialized_text = [self.vocab.stoi[\"<SOS>\"]]\n",
        "        numerialized_text += self.vocab.numericalize(text)\n",
        "        numerialized_text.append(self.vocab.stoi[\"<EOS>\"])\n",
        "    \n",
        "        label = [float(label)]\n",
        "        \n",
        "        return torch.tensor(numerialized_text), torch.tensor(label, requires_grad = True) "
      ],
      "metadata": {
        "id": "zOL_KhUUtX6m"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TrainDataset(\n",
        "    df = df, text_column = 'text', label_column = 'label', \n",
        "    freq_threshold = 10, vocab_size = 25000\n",
        ")\n",
        "\n",
        "print(f'{df.loc[1]}\\n')\n",
        "\n",
        "text, label = train_dataset[1]\n",
        "print(text)\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVRZ1OFMxw5j",
        "outputId": "5d81c3bf-12b1-40c2-ea17-61195337302e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text     a wonderful little production br br the filmin...\n",
            "label                                                    1\n",
            "Name: 1, dtype: object\n",
            "\n",
            "tensor([    1,     6,   531,   134,   493,    15,    15,     4,  2429,  6444,\n",
            "            9,    57,     3,    57,     3,  3052,     5,   544,     6,     3,\n",
            "            5,   757,     3,   373,     7,  3649,     8,     4,   587,   566,\n",
            "           15,    15,     4,   182,    26,   811,    79,  4561,   707, 10824,\n",
            "           24,    66,    48,   231,    34,     4,     3,    21,    30,    48,\n",
            "           34,     4,  4436,   232,  7214,   110,    25,    74,   482,    70,\n",
            "            4,     3,  1265,     3,    36,     4,  3442,     8,  3135, 20097,\n",
            "        17593,    24,    66,     9,    11,    79,   354,     4,   176,    21,\n",
            "           11,     9,     6,     3,   596,     5,  4817,   566,     6, 10040,\n",
            "          493,    46,    31,     7,     4,    87,  6974,     7,   270,     5,\n",
            "           27,   142,    15,    15,     4,  3649,    68,   344,   472,    18,\n",
            "            4,   134,   223,     4,  1819,     7,     4,  6358,    67,   308,\n",
            "           76,   466,     4,  4240,  1720,  6859,  2170,  1978,   101, 12157,\n",
            "           11,   381,    23,   327,  3447,     5,   327, 10825,   856,    18,\n",
            "            4,   160,  8053,     3,     5,     3,     5,     4,  1115,   856,\n",
            "            7,    69,  1870,    18,     3,     3,     3,   203,  4523,    26,\n",
            "         3688,    79,   283,    50,   655,     3,   595, 17594,     3, 13041,\n",
            "            3,  8131,     3,     3,     3, 15155,     3,  2498,  6860,  9423,\n",
            "          139,  4061,     3,     3,  1073,     3, 20292,     3,     3,     3,\n",
            "         2160,     3, 18585,     3,     3,     3, 22297,     3,   460,  5615,\n",
            "            3,     3,     3,     3, 14796,     3,     3,     3,     3, 19490,\n",
            "          320,     3,   744,  3978,     3,     3,     3,     3,     3, 23092,\n",
            "            3,     3,     3,  1336,  3036,   920,   455,     3,     3,     3,\n",
            "            3, 10706,    80,     3,   150, 17142,     3,     3,     3,     3,\n",
            "        18967,     3,     3,     3,     3,     3, 24838,     3,   205,     3,\n",
            "        13996,  5475,     3,     3,     3,     3,   833,  7384,  1971,  1184,\n",
            "         5505,     3, 14549,     3,   823,     3,     3,     3, 15389,     3,\n",
            "          216,  1379,     3,     3,     3,     3,     3,   129,     3,   612,\n",
            "            3, 12936,     3,  8168,     3,     3,     3,     3,     3,  2863,\n",
            "          122,    83,     3,   212,  1482,     3,  1434,  4391,     3,     3,\n",
            "          100,     3,  8574,     3,     3, 10081,     3,     3,     3,  3247,\n",
            "            3,  2827,     3,     3,     3,     3,     2])\n",
            "tensor([1.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, train_dataset, df, text_column, label_column):\n",
        "        self.train_dataset = train_dataset\n",
        "        self.df = df\n",
        "        \n",
        "        # get texts and labels\n",
        "        self.texts = self.df[text_column]\n",
        "        self.labels = self.df[label_column]\n",
        "        \n",
        "        # utilizing vocabulary created using training set\n",
        "        self.vocab = self.train_dataset.vocab\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        text = self.texts[int(index)]\n",
        "        label = self.labels[index]\n",
        "            \n",
        "        # numericalize texts ['<SOS>','cat', 'in', 'a', 'bag','<EOS>'] -> [1,12,2,9,24,2]\n",
        "        numerialized_text = [self.vocab.stoi[\"<SOS>\"]]\n",
        "        numerialized_text += self.vocab.numericalize(text)\n",
        "        numerialized_text.append(self.vocab.stoi[\"<EOS>\"])\n",
        "    \n",
        "        label = [float(label)]\n",
        "        \n",
        "        return torch.tensor(numerialized_text), torch.tensor(label, requires_grad = True) "
      ],
      "metadata": {
        "id": "d2xaA7uSxw8a"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = TestDataset(\n",
        "    train_dataset = train_dataset, df = df, text_column = 'text', label_column = 'label'\n",
        ")\n",
        "\n",
        "print(f'{df.loc[100]}\\n')\n",
        "\n",
        "text, label = test_dataset[100]\n",
        "print(text)\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3SRDnl4tX_d",
        "outputId": "73974cc6-d9b8-406f-e9b6-989984163929"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text     this short film that inspired the soontobe ful...\n",
            "label                                                    1\n",
            "Name: 100, dtype: object\n",
            "\n",
            "tensor([    1,    13,   456,    22,    14,  3021,     4,     3,   511,  3647,\n",
            "         1290,    35,     3,  6216,    35,     9,     6,   888,   566,    14,\n",
            "            3,   609,  1128,  4584,     3,  5296,  1439,     4,   456,    22,\n",
            "          577,  4802,     4,     3,    40,   111,   123,  8629,    39,    27,\n",
            "          385, 12397,    10,     4,   804,   609,     4,   658,     3,    13,\n",
            "         1350,  4187,    19,    51,   189,  2635,  1219,     4,   628,    21,\n",
            "            9,  1973,  1690,    19,     4, 23138,     7,     4,  1290,    13,\n",
            "          106,     3,   954,    65,     9, 23414,    36,    51,     3,   270,\n",
            "            5,     6,   550,  1060,   917,   663,    24,    78,   447,  2891,\n",
            "         3564,    11,     4,   133,    14,     9,   375,    62,   178,    68,\n",
            "           28,    65,     8,   138,    21,    32,  2416,  1851,    11,   133,\n",
            "          146,    76,   118,     3,   498,   106,    13,    22,     9,   354,\n",
            "          176,    33,   276,     6,   204,   271,   234,    11,    19,    53,\n",
            "           11,     9,     5,    98,   737,     6,  1378,    72,     3,     3,\n",
            "           50, 21393,  7138,   391,  6191,     3,  8679,     3,     3,     3,\n",
            "            3,     3,  6156,     3,     3,   249,     3,     3,     3,   731,\n",
            "            3,  1280,     3,   306,  5926,  3627,     3,   137,     3,     3,\n",
            "         1579,  4061,  2720,  4166,   315,  5036,  1475,     3, 24866,     3,\n",
            "          862,  3401,     3,  7686, 22079,     3, 23686,  4619,     3,  1254,\n",
            "            3,     3,     3,     3,     3,     3,     3,     3, 23687,     3,\n",
            "            3,     3,     3,   117,  1018,     3,  8832,  2445,     3,   898,\n",
            "           58,     3,   226,     3,   343,  3306,     3,  1397,  8427,     3,\n",
            "         4790,     3, 13062,     3,  2003,  4371,     3, 13063,     3,  1409,\n",
            "            3,  4643,     3,     3,  2590,     3,  2968,     3,     3, 22348,\n",
            "         8066,     3, 10469, 11448,     3,     3,  2401,     3,  6413,     3,\n",
            "         5845, 10666,  6209,     3,   817,     3,  4655,  7651,     3,     3,\n",
            "           83,   122,  9823,     3,     3,     3,  9619,  9770,     3,     3,\n",
            "            3,     3, 19934,     2])\n",
            "tensor([1.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCollate:\n",
        "    def __init__(self, pad_idx):\n",
        "        self.pad_idx = pad_idx\n",
        "        \n",
        "    def __call__(self, batch):\n",
        "        source = [item[0] for item in batch] \n",
        "        source = pad_sequence(source, batch_first=False, padding_value = self.pad_idx) \n",
        "        \n",
        "        target = torch.tensor([item[1].item() for item in batch])\n",
        "        return source, target"
      ],
      "metadata": {
        "id": "oPKcjRUezK-L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset = train_dataset, batch_size = 32, num_workers = 1, shuffle = True, pin_memory = True, drop_last = True,\n",
        "    collate_fn = MyCollate(pad_idx = train_dataset.vocab.stoi[\"<PAD>\"])\n",
        ")"
      ],
      "metadata": {
        "id": "gDYOViZdzLAh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset = test_dataset, batch_size = 64, num_workers = 1, shuffle = True, pin_memory = True,\n",
        "    collate_fn = MyCollate(pad_idx = train_dataset.vocab.stoi[\"<PAD>\"])\n",
        ")"
      ],
      "metadata": {
        "id": "LLbJ9c1Ez9qM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (texts, labels) in enumerate(train_loader):\n",
        "    print(texts.shape, labels.shape)\n",
        "    if idx >= 4:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6soBhtttYCD",
        "outputId": "05a47262-ba64-4484-e502-2d87ba0d66e4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1185, 32]) torch.Size([32])\n",
            "torch.Size([993, 32]) torch.Size([32])\n",
            "torch.Size([1876, 32]) torch.Size([32])\n",
            "torch.Size([1372, 32]) torch.Size([32])\n",
            "torch.Size([1204, 32]) torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for (text, label) in train_loader:\n",
        "    print(f\"{text.shape}\\n{type(text)}\\n{text}\")\n",
        "    print(f\"\\n{label.shape}\\n{type(label)}\\n{label}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdEjcpIkzj78",
        "outputId": "1a5dc857-79f3-449f-f261-6153634637f7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1151, 32])\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [1670,   12, 1248,  ...,   52,   79,   12],\n",
            "        [  12,   68,    3,  ...,   26,   11,  127],\n",
            "        ...,\n",
            "        [   0,    0,    0,  ...,    0,    0,    0],\n",
            "        [   0,    0,    0,  ...,    0,    0,    0],\n",
            "        [   0,    0,    0,  ...,    0,    0,    0]])\n",
            "\n",
            "torch.Size([32])\n",
            "<class 'torch.Tensor'>\n",
            "tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
            "        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lq32Ox1-z6wj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e7Gncd3fz7Hb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FastText(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx) \n",
        "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "    \n",
        "    def forward(self, text):\n",
        "        # text = [sent len, batch size]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "        embedded = embedded.permute(1, 0, 2)\n",
        "        # embedded = [batch size, sent len, emb dim]\n",
        "        pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1)\n",
        "        # pooled = [batch size, embedding_dim]\n",
        "        return self.fc(pooled)"
      ],
      "metadata": {
        "id": "tsQ6mp_Kk8ir"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X0x1va7MKVxj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = train_dataset.vocab.__len__()\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM = 1\n",
        "PAD_IDX = train_dataset.vocab.stoi[\"<PAD>\"]\n",
        "\n",
        "model = FastText(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)"
      ],
      "metadata": {
        "id": "Xq_W-jW4k8lO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc4GGg0Mk8nr",
        "outputId": "0cc0d1a3-8324-4fdd-e845-34e8398c9f5b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 2,500,101 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "pneRFr_Dk8qU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5VThOKrE03EL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "CYkhcwtMk9KD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "-b2vLjV-k9NL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        text, label = batch\n",
        "        text, label = text.to(device), label.to(device)\n",
        "                \n",
        "        predictions = model(text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "metadata": {
        "id": "lGjMTnhnk9PJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text, label = batch\n",
        "            text, label = text.to(device), label.to(device)\n",
        "\n",
        "            predictions = model(text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "nA4ckO-uk9Rt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "QSFsj3pqk9UI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 20\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, test_loader, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwdnyrink9W4",
        "outputId": "ddd11451-cecf-430d-c26b-827e0ca429c7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 45s\n",
            "\tTrain Loss: 0.613 | Train Acc: 72.36%\n",
            "\t Val. Loss: 0.495 |  Val. Acc: 85.06%\n",
            "Epoch: 02 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.390 | Train Acc: 87.36%\n",
            "\t Val. Loss: 0.342 |  Val. Acc: 89.45%\n",
            "Epoch: 03 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.296 | Train Acc: 90.01%\n",
            "\t Val. Loss: 0.278 |  Val. Acc: 91.11%\n",
            "Epoch: 04 | Epoch Time: 0m 44s\n",
            "\tTrain Loss: 0.252 | Train Acc: 91.32%\n",
            "\t Val. Loss: 0.242 |  Val. Acc: 92.13%\n",
            "Epoch: 05 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.223 | Train Acc: 92.26%\n",
            "\t Val. Loss: 0.217 |  Val. Acc: 93.00%\n",
            "Epoch: 06 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.200 | Train Acc: 93.08%\n",
            "\t Val. Loss: 0.195 |  Val. Acc: 93.73%\n",
            "Epoch: 07 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.183 | Train Acc: 93.77%\n",
            "\t Val. Loss: 0.178 |  Val. Acc: 94.37%\n",
            "Epoch: 08 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.169 | Train Acc: 94.36%\n",
            "\t Val. Loss: 0.164 |  Val. Acc: 94.92%\n",
            "Epoch: 09 | Epoch Time: 0m 43s\n",
            "\tTrain Loss: 0.155 | Train Acc: 94.87%\n",
            "\t Val. Loss: 0.151 |  Val. Acc: 95.48%\n",
            "Epoch: 10 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.142 | Train Acc: 95.38%\n",
            "\t Val. Loss: 0.140 |  Val. Acc: 95.92%\n",
            "Epoch: 11 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.132 | Train Acc: 95.82%\n",
            "\t Val. Loss: 0.129 |  Val. Acc: 96.35%\n",
            "Epoch: 12 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.123 | Train Acc: 96.22%\n",
            "\t Val. Loss: 0.121 |  Val. Acc: 96.68%\n",
            "Epoch: 13 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.114 | Train Acc: 96.58%\n",
            "\t Val. Loss: 0.112 |  Val. Acc: 97.03%\n",
            "Epoch: 14 | Epoch Time: 0m 43s\n",
            "\tTrain Loss: 0.106 | Train Acc: 96.89%\n",
            "\t Val. Loss: 0.103 |  Val. Acc: 97.34%\n",
            "Epoch: 15 | Epoch Time: 0m 41s\n",
            "\tTrain Loss: 0.097 | Train Acc: 97.19%\n",
            "\t Val. Loss: 0.097 |  Val. Acc: 97.59%\n",
            "Epoch: 16 | Epoch Time: 0m 41s\n",
            "\tTrain Loss: 0.090 | Train Acc: 97.45%\n",
            "\t Val. Loss: 0.090 |  Val. Acc: 97.83%\n",
            "Epoch: 17 | Epoch Time: 0m 41s\n",
            "\tTrain Loss: 0.085 | Train Acc: 97.70%\n",
            "\t Val. Loss: 0.083 |  Val. Acc: 98.09%\n",
            "Epoch: 18 | Epoch Time: 0m 41s\n",
            "\tTrain Loss: 0.077 | Train Acc: 97.95%\n",
            "\t Val. Loss: 0.077 |  Val. Acc: 98.33%\n",
            "Epoch: 19 | Epoch Time: 0m 43s\n",
            "\tTrain Loss: 0.072 | Train Acc: 98.19%\n",
            "\t Val. Loss: 0.071 |  Val. Acc: 98.56%\n",
            "Epoch: 20 | Epoch Time: 0m 41s\n",
            "\tTrain Loss: 0.066 | Train Acc: 98.37%\n",
            "\t Val. Loss: 0.065 |  Val. Acc: 98.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvqw2LUtk9ZL",
        "outputId": "6d9f02a2-5d94-4407-dabb-9593c41213a3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.066 | Test Acc: 98.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text, model, device):\n",
        "    ids = train_dataset.vocab.numericalize(text)\n",
        "    tensor = torch.LongTensor(ids).unsqueeze(dim=1).to(device)\n",
        "    prediction = model(tensor).squeeze(dim=1)\n",
        "    predicted_probability = torch.sigmoid(prediction).item()\n",
        "    predicted_class = torch.round(torch.tensor(predicted_probability))\n",
        "    print(f\"{'Negative' if predicted_class == 0 else 'Positive'} | probability score = {predicted_probability:.4f}\")"
      ],
      "metadata": {
        "id": "qAAXqdfak9b7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(\"This film is terrible\", model, device)"
      ],
      "metadata": {
        "id": "l787CoWvk9eG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32f6e4f-65d8-40be-8057-ddc727595a54"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative | probability score = 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(\"This film is great\", model, device)"
      ],
      "metadata": {
        "id": "qtMUor-Vk9gb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b05a8105-3a08-488b-e537-68e613bf94e8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive | probability score = 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hZoWylvuk9iz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QlKpnT7Bk9lN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qwG4dsUKk9nr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UytQtkfQk9qD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u0zjXQ5ok9s3"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t1F95HVbk9vU"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}