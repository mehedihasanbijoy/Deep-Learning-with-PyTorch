{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install text-preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M4w_UW0tW0r",
        "outputId": "a9cab256-60ce-4fe8-e490-ea10785ce409"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting text-preprocessing\n",
            "  Downloading text_preprocessing-0.1.1-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from text-preprocessing) (3.7)\n",
            "Collecting names-dataset==2.1\n",
            "  Downloading names_dataset-2.1.0-py3-none-any.whl (62.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 62.6 MB 233 kB/s \n",
            "\u001b[?25hCollecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.7.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 59.0 MB/s \n",
            "\u001b[?25hCollecting unittest-xml-reporting\n",
            "  Downloading unittest_xml_reporting-3.2.0-py2.py3-none-any.whl (20 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 75.4 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (110 kB)\n",
            "\u001b[K     |████████████████████████████████| 110 kB 74.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->text-preprocessing) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk->text-preprocessing) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->text-preprocessing) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->text-preprocessing) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from unittest-xml-reporting->text-preprocessing) (4.9.2)\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, unittest-xml-reporting, pyspellchecker, names-dataset, contractions, text-preprocessing\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.73 names-dataset-2.1.0 pyahocorasick-1.4.4 pyspellchecker-0.7.1 text-preprocessing-0.1.1 textsearch-0.0.24 unittest-xml-reporting-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from text_preprocessing import preprocess_text\n",
        "from text_preprocessing import to_lower, remove_email, remove_url, remove_punctuation\n",
        "\n",
        "preprocess_functions = [to_lower, remove_email, remove_url, remove_punctuation]\n",
        "\n",
        "def clean_text(text):\n",
        "    return preprocess_text(text, preprocess_functions)"
      ],
      "metadata": {
        "id": "EdoKVSFItYiT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb26dc2f-64f4-4492-ef12-ecf79605d844"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment2label(sentiment):\n",
        "    return 0 if sentiment == 'negative' else 1"
      ],
      "metadata": {
        "id": "BGDzjCZGtXmr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/PyTorch/PyTorch-NLP-Tutorial/Corpus/IMDB Dataset.csv')\n",
        "df['text'] = df['review'].apply(clean_text)\n",
        "df['label'] = df['sentiment'].apply(sentiment2label)\n",
        "df = df[['text', 'label']]\n",
        "df = df.sample(frac=1)\n",
        "df.dropna(inplace=True) \n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "gezKwpMZtXuF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = df.iloc[:int(len(df)*0.8), :].reset_index(drop=True)\n",
        "test_df = df.iloc[int(len(df)*0.8):, :].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "m0IuhYQ7fmZP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary: \n",
        "    def __init__(self, freq_threshold=10, max_size=100000):\n",
        "        '''\n",
        "        freq_threshold : the minimum times a word must occur in corpus to be included in vocabulary\n",
        "        max_size : max vocab size\n",
        "        '''\n",
        "        self.freq_threshold = freq_threshold\n",
        "        self.max_size = max_size\n",
        "\n",
        "        self.itos = {0: '<PAD>', 1:'<SOS>', 2:'<EOS>', 3: '<UNK>'}\n",
        "        self.stoi = {k:j for j, k in self.itos.items()} \n",
        "          \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "    \n",
        "\n",
        "    @staticmethod\n",
        "    def tokenizer(text):\n",
        "        return [tok.lower().strip() for tok in text.split(' ')]\n",
        "    \n",
        "    \n",
        "    def build_vocabulary(self, sentence_list):\n",
        "        '''\n",
        "        build the vocabulary: create a dictionary mapping of index to string (itos) and string to index (stoi)\n",
        "        (itos) -> {5:'the', 6:'a', 7:'an'} | (stoi) -> {'the':5, 'a':6, 'an':7}\n",
        "        '''\n",
        "        frequencies = {} \n",
        "        idx = 4  # because 4 tokens already added -> (itos) -> {0: '<PAD>', 1:'<SOS>', 2:'<EOS>', 3: '<UNK>'}\n",
        "        \n",
        "        # calculate the freq of words\n",
        "        for sentence in sentence_list:\n",
        "            for word in self.tokenizer(sentence):\n",
        "                if word not in frequencies.keys():\n",
        "                    frequencies[word] = 1\n",
        "                else:\n",
        "                    frequencies[word] += 1\n",
        "                    \n",
        "                    \n",
        "        # limit vocab by removing low freq words\n",
        "        frequencies = {k:v for k,v in frequencies.items() if v > self.freq_threshold} \n",
        "        \n",
        "        # limit vocab to the max_size specified\n",
        "        frequencies = dict(sorted(frequencies.items(), key = lambda x: -x[1])[:self.max_size-idx]) # idx = 4 for pad, start, end , unk\n",
        "            \n",
        "        # create vocab\n",
        "        for word in frequencies.keys():\n",
        "            self.stoi[word] = idx\n",
        "            self.itos[idx] = word\n",
        "            idx += 1\n",
        "\n",
        " \n",
        "    def numericalize(self, text):\n",
        "        '''\n",
        "        convert the list of words to a list of corresponding indexes\n",
        "        eg. cat and a dog -> [4, 5, 6, 3]\n",
        "        '''   \n",
        "        tokenized_text = self.tokenizer(text)  # tokenize text \n",
        "        numericalized_text = []\n",
        "\n",
        "        for token in tokenized_text:\n",
        "            if token in self.stoi.keys():\n",
        "                numericalized_text.append(self.stoi[token])\n",
        "            else: # out-of-vocab (OOV) words are represented by UNK token index\n",
        "                numericalized_text.append(self.stoi['<UNK>'])\n",
        "                \n",
        "        return numericalized_text"
      ],
      "metadata": {
        "id": "_nH53zlbtX1k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "metadata": {
        "id": "wPwxAk9jxx_m"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df, text_column, label_column, freq_threshold=5, vocab_size=10000):\n",
        "        self.df = df\n",
        "        \n",
        "        # get texts and labels\n",
        "        self.texts = self.df[text_column]\n",
        "        self.labels = self.df[label_column]\n",
        "        \n",
        "        # build vocabulary\n",
        "        self.vocab = Vocabulary(freq_threshold, vocab_size)\n",
        "        self.vocab.build_vocabulary(self.texts.tolist())\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        text = self.texts[int(index)]\n",
        "        label = self.labels[index]\n",
        "            \n",
        "        # numericalize texts ['<SOS>','cat', 'in', 'a', 'bag','<EOS>'] -> [1,12,2,9,24,2]\n",
        "        numerialized_text = [self.vocab.stoi[\"<SOS>\"]]\n",
        "        numerialized_text += self.vocab.numericalize(text)\n",
        "        numerialized_text.append(self.vocab.stoi[\"<EOS>\"])\n",
        "    \n",
        "        label = [float(label)]\n",
        "        \n",
        "        return torch.tensor(numerialized_text), torch.tensor(label, requires_grad = True) "
      ],
      "metadata": {
        "id": "zOL_KhUUtX6m"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TrainDataset(\n",
        "    df = train_df, text_column = 'text', label_column = 'label', \n",
        "    freq_threshold = 10, vocab_size = 25000\n",
        ")\n",
        "\n",
        "print(f'{df.loc[1]}\\n')\n",
        "\n",
        "text, label = train_dataset[1]\n",
        "print(text)\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVRZ1OFMxw5j",
        "outputId": "19f52715-55c8-41fe-85d5-21c2d0913475"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text     when i was younger this movie always aired on ...\n",
            "label                                                    1\n",
            "Name: 1, dtype: object\n",
            "\n",
            "tensor([    1,    54,    12,    16,  1068,    13,    20,   205,  3141,    23,\n",
            "         2495,   317,    10,     4,  1491,    23,  1176,  1902,    13,    16,\n",
            "            4,   155,   160,  1769,    16,     6,  2310,     5,   538,   130,\n",
            "            4,  7957,    12,   205,   564,   978,     8,    11,   460,   142,\n",
            "        10870,  6472,    19,    57,   735,    94,   844,   188,    19,    57,\n",
            "            3,   243,  2755,     5,     6,   799,   984,     3,    64,    63,\n",
            "            7,     4,  1281,    12,    16,  1506,     8,  2803, 23424,     5,\n",
            "          345,   250,     4,   234,     9,  6302,   540,  1008,    42,   116,\n",
            "        21516,    21,    32,     6,   247,    20,     5,    12,   422,  8191,\n",
            "            5, 17492,   982,  4136,     3,    19,   116,   791,    10,     4,\n",
            "           20,    21,    30,     9,  1244,  3155,   114, 18036,     5,   146,\n",
            "         5933,  4735, 13553,  1191,     7,     4,  9118,  1353, 19257,     9,\n",
            "          180,    76,     4,   167,   112,    30,   248,    10,    57,  8309,\n",
            "           21,    30,   125,    11,    41,    77,     2])\n",
            "tensor([1.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, train_dataset, df, text_column, label_column):\n",
        "        self.train_dataset = train_dataset\n",
        "        self.df = df\n",
        "        \n",
        "        # get texts and labels\n",
        "        self.texts = self.df[text_column]\n",
        "        self.labels = self.df[label_column]\n",
        "        \n",
        "        # utilizing vocabulary created using training set\n",
        "        self.vocab = self.train_dataset.vocab\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        text = self.texts[int(index)]\n",
        "        label = self.labels[index]\n",
        "            \n",
        "        # numericalize texts ['<SOS>','cat', 'in', 'a', 'bag','<EOS>'] -> [1,12,2,9,24,2]\n",
        "        numerialized_text = [self.vocab.stoi[\"<SOS>\"]]\n",
        "        numerialized_text += self.vocab.numericalize(text)\n",
        "        numerialized_text.append(self.vocab.stoi[\"<EOS>\"])\n",
        "    \n",
        "        label = [float(label)]\n",
        "        \n",
        "        return torch.tensor(numerialized_text), torch.tensor(label, requires_grad = True) "
      ],
      "metadata": {
        "id": "d2xaA7uSxw8a"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = TestDataset(\n",
        "    train_dataset = train_dataset, df = test_df, text_column = 'text', label_column = 'label'\n",
        ")\n",
        "\n",
        "print(f'{df.loc[100]}\\n')\n",
        "\n",
        "text, label = test_dataset[100]\n",
        "print(text)\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3SRDnl4tX_d",
        "outputId": "30afb9ea-acb7-4cc2-fdc5-41072903d8c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text     i cant say that this movie deserves a ten beca...\n",
            "label                                                    1\n",
            "Name: 100, dtype: object\n",
            "\n",
            "tensor([    1,   679,  2393,   829,    17,    44,   158,  6242,     7,   116,\n",
            "          377,   569,  2592,     6,   692,   364,    19,   679, 14823,  1029,\n",
            "        24300,  2393,    48,    27,   922,   376,   258,     8,   380,    99,\n",
            "           10,   372,     5,  3110,    99,    10,    67, 20639, 13815,    52,\n",
            "          504,     4,    22,   185,     9,     4,  2193,  1264,     7,     6,\n",
            "          170,   362,   346,    50,  1402,   132,     4,    91,  7917,   204,\n",
            "          160,   576,  2401, 15082,     4,   196,   290,    39,     4,    63,\n",
            "            4,   454,  8531,   839,     7,  2674, 19919,   305,  5588,   709,\n",
            "           33,  2222,     3,  8800,  2525,  4734, 22298,    27, 22191,     5,\n",
            "         4074,  4102,    23,     4,   354,     7,     4,   181,   679,  2393,\n",
            "          459,    76,    56,    74,    44,     6,  2266,  7382,    15,   157,\n",
            "         5588,     9,     4,   275,   284,     8,   107,   679,  2393,    51,\n",
            "           26,    82,  5704,     7,  3891,     8,   345,     3,   175,   500,\n",
            "        15488,   310,  1823,    18,   140,  5232,    17,  8159,     5,  6627,\n",
            "         6671,     3,   755,  1114,    19,    27,   386,  7878,    36,  4343,\n",
            "         6118,     3,     7,  4476,   203,     6,  1040,  2095,    14,  3710,\n",
            "           10,     4,   731,   344,    18,   475,     4, 15106,  4734,    14,\n",
            "        16203,    91, 15977,  4688,     3,  4272,  7255, 12876,    23,    41,\n",
            "        23795,   459,  5247,     7,     4,  6833,    10, 10565,     5, 10560,\n",
            "           36,   146,    40,   342,   596,    15,    14,  5588,  1458,     4,\n",
            "         4846,   240,     9,   595,    21,     4,   354,     7,     4,   181,\n",
            "          914,    60,    19,    92,    90,     7,     4,   100,     4,  2010,\n",
            "         4272,  7255,   292,    27,   218,     8,  3384,    17,     4,  7280,\n",
            "        15977,   615,   114,    18,    27, 14490,  2222,   113, 15351,    58,\n",
            "           54,   451,    19,   158,   136,  4774, 12065,   658,  3339,    17,\n",
            "            4,   364,     7,     4,   679, 12397,   186,   377,   394,     6,\n",
            "          487,  1079,     7,     6,   281,   683, 20315,   238,   420,    40,\n",
            "          207,   435,    10,     4, 16845,     4,   287,  2525,  1801,   463,\n",
            "          828,    18,    67,   698,  3783,   477,    84,  3777,  1615,   392,\n",
            "           67,   506,    77,     6, 10704,     7,   715,   153,   580,  2199,\n",
            "            3,  1230, 23324,   200, 14790,     5,  1875,     3,   161,    11,\n",
            "           34,  9035,    15,    89, 16109,  5837,     9,   174,     7,     4,\n",
            "        10100,    18,  1319,     4,  1625,     7,     4,   731,  1563,  2222,\n",
            "            9,     4,  5712,     3,    58,    54,    62,     5,  2674,    26,\n",
            "          188,     5,    49,    62,   205,   277,    23,     4,  1839,   517,\n",
            "            5,    42,    41,   108,  1004,    10,     4,     3,     7,     4,\n",
            "           83,  4010,    10,   146,   488,    62,   208, 24679,    44,   185,\n",
            "            4,  3337,  2674, 21410,    37,   429,  1056,     7,    85,   183,\n",
            "           14,    28,   579,     8,    92,  3119,  1083,    10,    27,  5008,\n",
            "           39,  2222,    65,  2222,  3226,     8,    86,  2674,  5680,     8,\n",
            "          142,    49,    19,     6, 15398,     7,  7276,  3336,    92,   359,\n",
            "           17,    30,  6984,     4,  3337,     7,   124,  2674,    48, 13077,\n",
            "          633,    17,     6,  4651,  2222,    48,   633,     8,  3575,    17,\n",
            "            6,  1940,     5,  5484,  2222,     9,   196,    23,   904,  2674,\n",
            "            9,   196,    23,  1557,    10,     6,  8659,   285,     7,     6,\n",
            "          100,     5,     4,  3942,   142,    23,     5,    23,    89,    34,\n",
            "           13,     9, 24288,    10,     4,   134,     9,    37,   670,   174,\n",
            "            7,     4,    20,    24,     8,    29, 20012,    15,    68,   679,\n",
            "         2393,    18,   305, 21885, 20549,     7,    37,   117,  2004,    23,\n",
            "            4,   196,   290,     4,    64,    63,    30,    16,   127,   373,\n",
            "         1696,   155,   310,    54,    30,   178, 12468,     4,    22,  9823,\n",
            "           19,    31,     7,     4,   759,   290,   357,   123,    17,  1230,\n",
            "        19412,    10,     4, 11554,   205,  2845,  1487,  1775,     4,  1359,\n",
            "         3631, 12526,  4293,    21,    80,   107,   679,  2393,     8,  1251,\n",
            "          670,   790,    14,   200,    29,  1057,    47,   103,    76,  8653,\n",
            "            9,  2631,    23,     4,   346,     7,     4,   122,     2])\n",
            "tensor([1.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCollate:\n",
        "    def __init__(self, pad_idx):\n",
        "        self.pad_idx = pad_idx\n",
        "        \n",
        "    def __call__(self, batch):\n",
        "        source = [item[0] for item in batch] \n",
        "        source = pad_sequence(source, batch_first=True, padding_value = self.pad_idx) \n",
        "        \n",
        "        target = torch.tensor([item[1].item() for item in batch])\n",
        "        return source, target"
      ],
      "metadata": {
        "id": "oPKcjRUezK-L"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset = train_dataset, batch_size = 32, num_workers = 1, shuffle = True, pin_memory = True, drop_last = True,\n",
        "    collate_fn = MyCollate(pad_idx = train_dataset.vocab.stoi[\"<PAD>\"])\n",
        ")"
      ],
      "metadata": {
        "id": "gDYOViZdzLAh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset = test_dataset, batch_size = 64, num_workers = 1, shuffle = True, pin_memory = True, \n",
        "    collate_fn = MyCollate(pad_idx = train_dataset.vocab.stoi[\"<PAD>\"])\n",
        ")"
      ],
      "metadata": {
        "id": "LLbJ9c1Ez9qM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (texts, labels) in enumerate(train_loader):\n",
        "    print(texts.shape, labels.shape)\n",
        "    if idx >= 4:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6soBhtttYCD",
        "outputId": "c48c51a6-7c7f-4acf-bc4a-a46591c2d450"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 903]) torch.Size([32])\n",
            "torch.Size([32, 747]) torch.Size([32])\n",
            "torch.Size([32, 764]) torch.Size([32])\n",
            "torch.Size([32, 1002]) torch.Size([32])\n",
            "torch.Size([32, 971]) torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for (text, label) in train_loader:\n",
        "    print(f\"{text.shape}\\n{type(text)}\\n{text}\")\n",
        "    print(f\"\\n{label.shape}\\n{type(label)}\\n{label}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdEjcpIkzj78",
        "outputId": "6f55cd5e-9495-43e0-d71b-c96850c8f477"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 806])\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[   1,   32,    4,  ...,    0,    0,    0],\n",
            "        [   1,    4,  875,  ...,    0,    0,    0],\n",
            "        [   1, 1603, 4192,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [   1,    3,    9,  ...,    0,    0,    0],\n",
            "        [   1,   58,   18,  ...,    0,    0,    0],\n",
            "        [   1,   12,   16,  ...,    0,    0,    0]])\n",
            "\n",
            "torch.Size([32])\n",
            "<class 'torch.Tensor'>\n",
            "tensor([0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
            "        0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lq32Ox1-z6wj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e7Gncd3fz7Hb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        \n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        \n",
        "        return self.fc(hidden.squeeze(0))"
      ],
      "metadata": {
        "id": "tsQ6mp_Kk8ir"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BagOfWords(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_index):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_index)\n",
        "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "    \n",
        "    def forward(self, ids):\n",
        "        # ids = [batch size, seq len]\n",
        "        embedded = self.embedding(ids)\n",
        "        # embedded = [batch size, seq len, embedding dim]\n",
        "        pooled = embedded.mean(dim=1)\n",
        "        # pooled = [batch size, embedding dim]\n",
        "        prediction = self.fc(pooled)\n",
        "        # prediction = [batch size, output dim]\n",
        "        return prediction\n"
      ],
      "metadata": {
        "id": "MbSE14zRmvO7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = train_dataset.vocab.__len__()\n",
        "embedding_dim = 256\n",
        "output_dim = 2\n",
        "pad_index = train_dataset.vocab.stoi[\"<PAD>\"]\n",
        "\n",
        "model = BagOfWords(vocab_size, embedding_dim, output_dim, pad_index)"
      ],
      "metadata": {
        "id": "hlOdJ9hCnfyd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc4GGg0Mk8nr",
        "outputId": "b820350f-df6f-4085-b102-f2c530db9bac"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 6,400,514 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "pneRFr_Dk8qU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "CYkhcwtMk9KD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(prediction, label):\n",
        "    batch_size, _ = prediction.shape\n",
        "    predicted_classes = prediction.argmax(dim=-1)\n",
        "    correct_predictions = predicted_classes.eq(label).sum()\n",
        "    accuracy = correct_predictions / batch_size\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "xxnU2rxdo-hV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm, sys\n",
        "\n",
        "def train(dataloader, model, criterion, optimizer, device):\n",
        "\n",
        "    model.train()\n",
        "    epoch_losses = []\n",
        "    epoch_accs = []\n",
        "\n",
        "    for batch in tqdm.tqdm(dataloader, desc='training...', file=sys.stdout):\n",
        "        ids, label = batch\n",
        "        ids, label = ids.to(device), label.type(torch.LongTensor).to(device)\n",
        "        prediction = model(ids)\n",
        "        loss = criterion(prediction, label)\n",
        "        accuracy = get_accuracy(prediction, label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_losses.append(loss.item())\n",
        "        epoch_accs.append(accuracy.item())\n",
        "\n",
        "    return epoch_losses, epoch_accs\n"
      ],
      "metadata": {
        "id": "24ARHx9PouaE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader, model, criterion, device):\n",
        "    \n",
        "    model.eval()\n",
        "    epoch_losses = []\n",
        "    epoch_accs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm.tqdm(dataloader, desc='evaluating...', file=sys.stdout):\n",
        "            ids, label = batch\n",
        "            ids, label = ids.to(device), label.type(torch.LongTensor).to(device)\n",
        "            prediction = model(ids)\n",
        "            loss = criterion(prediction, label)\n",
        "            accuracy = get_accuracy(prediction, label)\n",
        "            epoch_losses.append(loss.item())\n",
        "            epoch_accs.append(accuracy.item())\n",
        "\n",
        "    return epoch_losses, epoch_accs"
      ],
      "metadata": {
        "id": "nA4ckO-uk9Rt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "n_epochs = 20\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "valid_losses = []\n",
        "valid_accs = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    train_loss, train_acc = train(train_loader, model, criterion, optimizer, device)\n",
        "    valid_loss, valid_acc = evaluate(test_loader, model, criterion, device)\n",
        "\n",
        "    train_losses.extend(train_loss)\n",
        "    train_accs.extend(train_acc)\n",
        "    valid_losses.extend(valid_loss)\n",
        "    valid_accs.extend(valid_acc)\n",
        "    \n",
        "    epoch_train_loss = np.mean(train_loss)\n",
        "    epoch_train_acc = np.mean(train_acc)\n",
        "    epoch_valid_loss = np.mean(valid_loss)\n",
        "    epoch_valid_acc = np.mean(valid_acc)\n",
        "    \n",
        "    if epoch_valid_loss < best_valid_loss:\n",
        "        best_valid_loss = epoch_valid_loss\n",
        "        torch.save(model.state_dict(), 'nbow.pt')\n",
        "    \n",
        "    print(f'epoch: {epoch+1}')\n",
        "    print(f'train_loss: {epoch_train_loss:.3f}, train_acc: {epoch_train_acc:.3f}')\n",
        "    print(f'valid_loss: {epoch_valid_loss:.3f}, valid_acc: {epoch_valid_acc:.3f}')\n"
      ],
      "metadata": {
        "id": "QSFsj3pqk9UI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6fae596-aa15-400c-b40d-4869db9f7e9a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training...: 100%|██████████| 1250/1250 [00:14<00:00, 86.68it/s] \n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 68.95it/s]\n",
            "epoch: 1\n",
            "train_loss: 0.518, train_acc: 0.777\n",
            "valid_loss: 0.388, valid_acc: 0.864\n",
            "training...: 100%|██████████| 1250/1250 [00:12<00:00, 103.11it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 67.97it/s]\n",
            "epoch: 2\n",
            "train_loss: 0.303, train_acc: 0.892\n",
            "valid_loss: 0.298, valid_acc: 0.892\n",
            "training...: 100%|██████████| 1250/1250 [00:11<00:00, 108.37it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 68.70it/s]\n",
            "epoch: 3\n",
            "train_loss: 0.237, train_acc: 0.917\n",
            "valid_loss: 0.273, valid_acc: 0.900\n",
            "training...: 100%|██████████| 1250/1250 [00:11<00:00, 107.29it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 68.78it/s]\n",
            "epoch: 4\n",
            "train_loss: 0.202, train_acc: 0.931\n",
            "valid_loss: 0.256, valid_acc: 0.906\n",
            "training...: 100%|██████████| 1250/1250 [00:11<00:00, 107.89it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 68.34it/s]\n",
            "epoch: 5\n",
            "train_loss: 0.175, train_acc: 0.942\n",
            "valid_loss: 0.248, valid_acc: 0.906\n",
            "training...: 100%|██████████| 1250/1250 [00:13<00:00, 95.41it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 67.10it/s]\n",
            "epoch: 6\n",
            "train_loss: 0.152, train_acc: 0.950\n",
            "valid_loss: 0.249, valid_acc: 0.906\n",
            "training...: 100%|██████████| 1250/1250 [00:11<00:00, 107.12it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 69.28it/s]\n",
            "epoch: 7\n",
            "train_loss: 0.135, train_acc: 0.958\n",
            "valid_loss: 0.254, valid_acc: 0.904\n",
            "training...: 100%|██████████| 1250/1250 [00:11<00:00, 108.70it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 68.81it/s]\n",
            "epoch: 8\n",
            "train_loss: 0.119, train_acc: 0.963\n",
            "valid_loss: 0.258, valid_acc: 0.903\n",
            "training...: 100%|██████████| 1250/1250 [00:11<00:00, 107.24it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 68.77it/s]\n",
            "epoch: 9\n",
            "train_loss: 0.106, train_acc: 0.968\n",
            "valid_loss: 0.268, valid_acc: 0.902\n",
            "training...: 100%|██████████| 1250/1250 [00:11<00:00, 108.69it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 69.97it/s]\n",
            "epoch: 10\n",
            "train_loss: 0.094, train_acc: 0.973\n",
            "valid_loss: 0.273, valid_acc: 0.900\n",
            "training...: 100%|██████████| 1250/1250 [00:11<00:00, 108.44it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 66.76it/s]\n",
            "epoch: 11\n",
            "train_loss: 0.084, train_acc: 0.977\n",
            "valid_loss: 0.289, valid_acc: 0.900\n",
            "training...: 100%|██████████| 1250/1250 [00:11<00:00, 108.33it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 68.15it/s]\n",
            "epoch: 12\n",
            "train_loss: 0.074, train_acc: 0.980\n",
            "valid_loss: 0.299, valid_acc: 0.897\n",
            "training...: 100%|██████████| 1250/1250 [00:11<00:00, 105.34it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 68.13it/s]\n",
            "epoch: 13\n",
            "train_loss: 0.065, train_acc: 0.983\n",
            "valid_loss: 0.317, valid_acc: 0.895\n",
            "training...: 100%|██████████| 1250/1250 [00:11<00:00, 109.14it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 70.14it/s]\n",
            "epoch: 14\n",
            "train_loss: 0.058, train_acc: 0.986\n",
            "valid_loss: 0.335, valid_acc: 0.893\n",
            "training...: 100%|██████████| 1250/1250 [00:11<00:00, 108.09it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 68.71it/s]\n",
            "epoch: 15\n",
            "train_loss: 0.051, train_acc: 0.988\n",
            "valid_loss: 0.345, valid_acc: 0.894\n",
            "training...: 100%|██████████| 1250/1250 [00:11<00:00, 108.44it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 64.93it/s]\n",
            "epoch: 16\n",
            "train_loss: 0.045, train_acc: 0.990\n",
            "valid_loss: 0.367, valid_acc: 0.890\n",
            "training...: 100%|██████████| 1250/1250 [00:11<00:00, 106.45it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 68.32it/s]\n",
            "epoch: 17\n",
            "train_loss: 0.040, train_acc: 0.992\n",
            "valid_loss: 0.383, valid_acc: 0.891\n",
            "training...: 100%|██████████| 1250/1250 [00:12<00:00, 101.93it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:03<00:00, 50.38it/s]\n",
            "epoch: 18\n",
            "train_loss: 0.034, train_acc: 0.993\n",
            "valid_loss: 0.411, valid_acc: 0.888\n",
            "training...: 100%|██████████| 1250/1250 [00:11<00:00, 106.40it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 67.28it/s]\n",
            "epoch: 19\n",
            "train_loss: 0.030, train_acc: 0.994\n",
            "valid_loss: 0.426, valid_acc: 0.886\n",
            "training...: 100%|██████████| 1250/1250 [00:11<00:00, 108.43it/s]\n",
            "evaluating...: 100%|██████████| 157/157 [00:02<00:00, 69.01it/s]\n",
            "epoch: 20\n",
            "train_loss: 0.026, train_acc: 0.995\n",
            "valid_loss: 0.446, valid_acc: 0.885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text, model, device):\n",
        "    ids = train_dataset.vocab.numericalize(text)\n",
        "    tensor = torch.LongTensor(ids).unsqueeze(dim=0).to(device)\n",
        "    prediction = model(tensor).squeeze(dim=0)\n",
        "    probability = torch.softmax(prediction, dim=-1)\n",
        "    predicted_class = prediction.argmax(dim=-1).item()\n",
        "    predicted_probability = probability[predicted_class].item()\n",
        "    print(f\"{'Negative' if predicted_class == 0 else 'Positive'} | probability score = {predicted_probability:.4f}\")"
      ],
      "metadata": {
        "id": "u0zjXQ5ok9s3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment('This film is terrible', model, device)"
      ],
      "metadata": {
        "id": "t1F95HVbk9vU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e3c80b6-2259-42f2-d064-ea588b2681c3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative | probability score = 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment('This film is great', model, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDEnbSysvaxI",
        "outputId": "aeebb625-0bdb-4064-d9d3-447842c11af4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive | probability score = 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9-1o0-wVvazt"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}