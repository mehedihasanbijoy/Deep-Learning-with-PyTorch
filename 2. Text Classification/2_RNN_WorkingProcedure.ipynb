{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## [1] Texts, Labels\n",
        "## [2] Numericized texts and labels\n",
        "## [3] Batch :: tuple(text, label)\n",
        "## [4] text → `EMBEDDING LAYER` → embedded text\n",
        "## [5] embedded text → `RNN LAYER` → output, hidden state\n",
        "## [6] hidden state → `LINEAR LAYER` → prediction"
      ],
      "metadata": {
        "id": "ipHilV5WrPBC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nt9MWo7fqziG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy examples\n",
        "texts = torch.tensor([[1 , 2], [2, 3], [3, 0]])  # [sentence length x batch size] → [3, 2]\n",
        "labels = torch.tensor([0, 1])  # [batch size] → [2]"
      ],
      "metadata": {
        "id": "uajxM3wpvRB8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "input_dim = 5  # vocabulary size\n",
        "embedding_dim = 3\n",
        "hidden_dim = 4\n",
        "output_dim = 3  # number of classes"
      ],
      "metadata": {
        "id": "m03nfhBQvRyy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding, rnn, and fc layers\n",
        "\n",
        "embedding = nn.Embedding(input_dim, embedding_dim)  \n",
        "# (input) texts :: [sentence length x batch size]\n",
        "# (output) embedded texts:: [sentence length x batch size x embedding dimension]\n",
        "\n",
        "rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "# (input) embedded texts :: [sentence length x batch size x embedding dimension]\n",
        "# (output_1) output :: [sentence length x batch size x hidden dimension]\n",
        "# (output_2) hidden state :: [1 x batch size x hidden dimension]\n",
        "\n",
        "fc = nn.Linear(hidden_dim, output_dim)\n",
        "# (input) last hidden state :: [1 x batch size x hidden dimension] → [batch size x hidden dimension]\n",
        "# (output) prediction :: [batch size x output dimension]"
      ],
      "metadata": {
        "id": "i6txgn_Bq8Tk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'texts:\\n{texts, texts.shape}\\n\\n\\n')\n",
        "\n",
        "embedded = embedding(texts) \n",
        "print(f'embedded text:\\n{embedded, embedded.shape}\\n\\n\\n')\n",
        "\n",
        "out, hid = rnn(embedded)\n",
        "print(f'output:\\n{out, out.shape}\\n')\n",
        "print(f'hidden state:\\n{hid, hid.shape}\\n\\n\\n')\n",
        "\n",
        "pred = fc(hid.squeeze())\n",
        "print(f'prediction:\\n{pred, pred.shape}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HPHMCJOq8WC",
        "outputId": "6af15b37-7c62-4ed3-f6a1-1f30466baf3c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texts:\n",
            "(tensor([[1, 2],\n",
            "        [2, 3],\n",
            "        [3, 0]]), torch.Size([3, 2]))\n",
            "\n",
            "\n",
            "\n",
            "embedded text:\n",
            "(tensor([[[-0.3114,  0.8579,  1.6065],\n",
            "         [-0.0717,  1.6152, -0.5619]],\n",
            "\n",
            "        [[-0.0717,  1.6152, -0.5619],\n",
            "         [ 0.8590, -0.4618,  0.6958]],\n",
            "\n",
            "        [[ 0.8590, -0.4618,  0.6958],\n",
            "         [ 2.5485,  1.4779,  0.5817]]], grad_fn=<EmbeddingBackward0>), torch.Size([3, 2, 3]))\n",
            "\n",
            "\n",
            "\n",
            "output:\n",
            "(tensor([[[ 0.3752,  0.5606,  0.2854, -0.2116],\n",
            "         [-0.6983, -0.4774,  0.8035, -0.1856]],\n",
            "\n",
            "        [[-0.7224, -0.2625,  0.8491,  0.2487],\n",
            "         [-0.0033,  0.7973,  0.5871, -0.7194]],\n",
            "\n",
            "        [[-0.1242,  0.8778,  0.5444, -0.7499],\n",
            "         [-0.8693,  0.7159,  0.9761, -0.6613]]], grad_fn=<StackBackward0>), torch.Size([3, 2, 4]))\n",
            "\n",
            "hidden state:\n",
            "(tensor([[[-0.1242,  0.8778,  0.5444, -0.7499],\n",
            "         [-0.8693,  0.7159,  0.9761, -0.6613]]], grad_fn=<StackBackward0>), torch.Size([1, 2, 4]))\n",
            "\n",
            "\n",
            "\n",
            "prediction:\n",
            "(tensor([[-0.1449,  0.5620, -0.3436],\n",
            "        [-0.3834,  0.4529, -0.0750]], grad_fn=<AddmmBackward0>), torch.Size([2, 3]))\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xd5Intwzq8Yq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}