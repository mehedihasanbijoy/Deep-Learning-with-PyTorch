{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Load the dataset"
      ],
      "metadata": {
        "id": "Iu0qqcYhbpQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "\n",
        "df = pd.read_csv('./corpus/TweetSentiment.csv')\n",
        "df = df[['cleaned_text', 'label']]\n",
        "df.dropna(inplace=True)\n",
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "do3UK9GS_GjP",
        "outputId": "7a748967-9b2f-4285-e04d-dd927233f827"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            cleaned_text  label\n",
              "3582   the wedding over everyone has gone home newlyw...    0.0\n",
              "30114               cinema tonight half the price monday    2.0\n",
              "28871  have both her cds and know them both heart rea...    0.0\n",
              "14648  rather sit bench with friendly psychiatric pat...    2.0\n",
              "7737                     try direct message here twitter    0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5dd7e059-d5be-42ef-aa6b-c70750b98f7e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3582</th>\n",
              "      <td>the wedding over everyone has gone home newlyw...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30114</th>\n",
              "      <td>cinema tonight half the price monday</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28871</th>\n",
              "      <td>have both her cds and know them both heart rea...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14648</th>\n",
              "      <td>rather sit bench with friendly psychiatric pat...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7737</th>\n",
              "      <td>try direct message here twitter</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dd7e059-d5be-42ef-aa6b-c70750b98f7e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5dd7e059-d5be-42ef-aa6b-c70750b98f7e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5dd7e059-d5be-42ef-aa6b-c70750b98f7e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the dataset into train and test sets"
      ],
      "metadata": {
        "id": "M9iafbulcFiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['cleaned_text'].tolist(),\n",
        "    df['label'].tolist(),\n",
        "    test_size = 0.2,\n",
        "    stratify = df['label'].tolist(),\n",
        "    random_state = 64\n",
        ")"
      ],
      "metadata": {
        "id": "5-UrSWfV_Gl2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# print the statistics of train and test sets\n",
        "print(f'Train data instances: {len(X_train)}\\nClass distribution: {Counter(y_train)}')\n",
        "print(f'\\nTest data instances: {len(X_test)}\\nClass distribution: {Counter(y_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D72QAyxs_Gri",
        "outputId": "67c7f65a-2c24-4303-ab4a-9aa3894c6812"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data instances: 24144\n",
            "Class distribution: Counter({0.0: 9660, 2.0: 7560, 1.0: 6924})\n",
            "\n",
            "Test data instances: 6037\n",
            "Class distribution: Counter({0.0: 2416, 2.0: 1890, 1.0: 1731})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# create iterator: list of tuples -> (label, text)\n",
        "train_data = list(zip(y_train, X_train))\n",
        "test_data = list(zip(y_test, X_test))\n",
        "\n",
        "# display training samples\n",
        "random.choices(train_data, k = 5)"
      ],
      "metadata": {
        "id": "MdH7kO5Q_Gup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e5129bd-cfd4-418c-a8a2-8fe6edf4bb41"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.0, 'wasnt was with the the time and now omw class what this new kaggra'),\n",
              " (2.0, 'yeah checked pretty nice site'),\n",
              " (2.0, 'omg that toooo funny'),\n",
              " (0.0, 'company policy has been for the last two places ive worked'),\n",
              " (1.0,\n",
              "  'sometimes forget favorite stars are real people too made orange chicken last night and cut his finger off sad')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "cGEOOiZ8dtC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "hgynYso-pyko"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchtext.data.utils import get_tokenizer\n",
        "# tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def tokenizer(x):\n",
        "    return x.lower().split()\n",
        "\n",
        "def yield_tokens(data_iterator):\n",
        "    for _, text in data_iterator:\n",
        "        yield tokenizer(text)"
      ],
      "metadata": {
        "id": "Mrolb0w9pysN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# build vocabulary\n",
        "VOCAB = build_vocab_from_iterator(yield_tokens(train_data), specials=[''])\n",
        "VOCAB.set_default_index(VOCAB[''])"
      ],
      "metadata": {
        "id": "g-eK3rMapyue"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create pipelines\n",
        "TEXT_PIPELINE = lambda x: VOCAB(tokenizer(x))\n",
        "LABEL_PIPELINE = lambda x: int(x)\n",
        "\n",
        "# pipelines in action\n",
        "print(TEXT_PIPELINE('This is an example'))\n",
        "print(LABEL_PIPELINE('2'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaSigbTwpyw5",
        "outputId": "30a6b784-2f84-4845-dcbc-0b1f58bf0158"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16, 0, 0, 7032]\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch collate function\n",
        "def collate_batch(batch):\n",
        "    labels, texts, offsets = [], [], [0]\n",
        "    for (label, text) in batch:\n",
        "        labels.append(LABEL_PIPELINE(label))\n",
        "        _texts = torch.tensor(TEXT_PIPELINE(text), dtype=torch.int64)\n",
        "        texts.append(_texts)\n",
        "        offsets.append(_texts.size(0))\n",
        "    labels = torch.tensor(labels, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    texts = torch.cat(texts)\n",
        "    return labels.to(DEVICE), texts.to(DEVICE), offsets.to(DEVICE)"
      ],
      "metadata": {
        "id": "51UQRV4CpyzV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# hyperparameters\n",
        "EPOCHS = 25\n",
        "LEARNING_RATE = 0.5\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# dataloaders\n",
        "train_loader = DataLoader(train_data, batch_size = BATCH_SIZE, shuffle = True, collate_fn = collate_batch)  # train data is train iterator\n",
        "test_loader = DataLoader(test_data, batch_size = BATCH_SIZE, shuffle = True, collate_fn = collate_batch)  # test data is test iterator"
      ],
      "metadata": {
        "id": "_xL7T7EhK0UB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Classification Model\n",
        "A feed-forward neural network"
      ],
      "metadata": {
        "id": "rc6nHzIghCG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FeedForwardNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(FeedForwardNN, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc1 = nn.Linear(embed_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 16)\n",
        "        self.fc4 = nn.Linear(16, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.68\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc1.bias.data.zero_()\n",
        "        self.fc2.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc2.bias.data.zero_()\n",
        "        self.fc3.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc3.bias.data.zero_()\n",
        "        self.fc4.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc4.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        x = F.relu(self.fc1(embedded))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vilqyyt3Er8a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = len(set([label for (label, text) in train_data]))\n",
        "VOCAB_SIZE = len(VOCAB)\n",
        "EMBED_SIZE = 128\n",
        "\n",
        "# initialize the model\n",
        "model = FeedForwardNN(VOCAB_SIZE, EMBED_SIZE, NUM_CLASSES).to(DEVICE)"
      ],
      "metadata": {
        "id": "hZRjvxWvYBuX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss fn, optimizer, scheduler\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)"
      ],
      "metadata": {
        "id": "-Hb5X0byYN3O"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Evaluate the Model"
      ],
      "metadata": {
        "id": "RklO8aP0hzCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 100\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predited_label = model(text, offsets)\n",
        "        loss = criterion(predited_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc/total_count))\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()"
      ],
      "metadata": {
        "id": "cRyXVh0nrwc9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predited_label = model(text, offsets)\n",
        "            loss = criterion(predited_label, label)\n",
        "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count"
      ],
      "metadata": {
        "id": "NfjCON_Lrwfg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_accu = None\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_loader)\n",
        "    accu_val = evaluate(test_loader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'test accuracy {:8.3f} '.format(epoch, time.time() - epoch_start_time, accu_val))\n",
        "    print('-' * 59)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOVLKVn8XLEI",
        "outputId": "ceed248f-7a6e-45b8-b8fb-39652df47975"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   100/  378 batches | accuracy    0.366\n",
            "| epoch   1 |   200/  378 batches | accuracy    0.405\n",
            "| epoch   1 |   300/  378 batches | accuracy    0.417\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time:  3.61s | test accuracy    0.427 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   100/  378 batches | accuracy    0.445\n",
            "| epoch   2 |   200/  378 batches | accuracy    0.443\n",
            "| epoch   2 |   300/  378 batches | accuracy    0.445\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time:  4.20s | test accuracy    0.433 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   100/  378 batches | accuracy    0.466\n",
            "| epoch   3 |   200/  378 batches | accuracy    0.464\n",
            "| epoch   3 |   300/  378 batches | accuracy    0.474\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time:  4.84s | test accuracy    0.463 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   100/  378 batches | accuracy    0.490\n",
            "| epoch   4 |   200/  378 batches | accuracy    0.500\n",
            "| epoch   4 |   300/  378 batches | accuracy    0.490\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time:  3.27s | test accuracy    0.482 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   100/  378 batches | accuracy    0.504\n",
            "| epoch   5 |   200/  378 batches | accuracy    0.509\n",
            "| epoch   5 |   300/  378 batches | accuracy    0.513\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time:  2.00s | test accuracy    0.497 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   100/  378 batches | accuracy    0.524\n",
            "| epoch   6 |   200/  378 batches | accuracy    0.520\n",
            "| epoch   6 |   300/  378 batches | accuracy    0.531\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time:  1.97s | test accuracy    0.498 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   100/  378 batches | accuracy    0.541\n",
            "| epoch   7 |   200/  378 batches | accuracy    0.543\n",
            "| epoch   7 |   300/  378 batches | accuracy    0.543\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time:  2.01s | test accuracy    0.530 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   100/  378 batches | accuracy    0.559\n",
            "| epoch   8 |   200/  378 batches | accuracy    0.554\n",
            "| epoch   8 |   300/  378 batches | accuracy    0.553\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time:  2.04s | test accuracy    0.523 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   100/  378 batches | accuracy    0.568\n",
            "| epoch   9 |   200/  378 batches | accuracy    0.573\n",
            "| epoch   9 |   300/  378 batches | accuracy    0.556\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time:  1.96s | test accuracy    0.534 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   100/  378 batches | accuracy    0.571\n",
            "| epoch  10 |   200/  378 batches | accuracy    0.573\n",
            "| epoch  10 |   300/  378 batches | accuracy    0.567\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time:  1.89s | test accuracy    0.540 \n",
            "-----------------------------------------------------------\n",
            "| epoch  11 |   100/  378 batches | accuracy    0.571\n",
            "| epoch  11 |   200/  378 batches | accuracy    0.564\n",
            "| epoch  11 |   300/  378 batches | accuracy    0.576\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  11 | time:  1.96s | test accuracy    0.536 \n",
            "-----------------------------------------------------------\n",
            "| epoch  12 |   100/  378 batches | accuracy    0.571\n",
            "| epoch  12 |   200/  378 batches | accuracy    0.577\n",
            "| epoch  12 |   300/  378 batches | accuracy    0.578\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  12 | time:  1.95s | test accuracy    0.538 \n",
            "-----------------------------------------------------------\n",
            "| epoch  13 |   100/  378 batches | accuracy    0.585\n",
            "| epoch  13 |   200/  378 batches | accuracy    0.567\n",
            "| epoch  13 |   300/  378 batches | accuracy    0.569\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  13 | time:  1.96s | test accuracy    0.538 \n",
            "-----------------------------------------------------------\n",
            "| epoch  14 |   100/  378 batches | accuracy    0.565\n",
            "| epoch  14 |   200/  378 batches | accuracy    0.584\n",
            "| epoch  14 |   300/  378 batches | accuracy    0.575\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  14 | time:  1.95s | test accuracy    0.538 \n",
            "-----------------------------------------------------------\n",
            "| epoch  15 |   100/  378 batches | accuracy    0.575\n",
            "| epoch  15 |   200/  378 batches | accuracy    0.577\n",
            "| epoch  15 |   300/  378 batches | accuracy    0.567\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  15 | time:  1.95s | test accuracy    0.538 \n",
            "-----------------------------------------------------------\n",
            "| epoch  16 |   100/  378 batches | accuracy    0.569\n",
            "| epoch  16 |   200/  378 batches | accuracy    0.572\n",
            "| epoch  16 |   300/  378 batches | accuracy    0.577\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  16 | time:  2.06s | test accuracy    0.538 \n",
            "-----------------------------------------------------------\n",
            "| epoch  17 |   100/  378 batches | accuracy    0.580\n",
            "| epoch  17 |   200/  378 batches | accuracy    0.571\n",
            "| epoch  17 |   300/  378 batches | accuracy    0.584\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  17 | time:  2.04s | test accuracy    0.538 \n",
            "-----------------------------------------------------------\n",
            "| epoch  18 |   100/  378 batches | accuracy    0.575\n",
            "| epoch  18 |   200/  378 batches | accuracy    0.576\n",
            "| epoch  18 |   300/  378 batches | accuracy    0.575\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  18 | time:  2.19s | test accuracy    0.538 \n",
            "-----------------------------------------------------------\n",
            "| epoch  19 |   100/  378 batches | accuracy    0.571\n",
            "| epoch  19 |   200/  378 batches | accuracy    0.577\n",
            "| epoch  19 |   300/  378 batches | accuracy    0.571\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  19 | time:  1.91s | test accuracy    0.538 \n",
            "-----------------------------------------------------------\n",
            "| epoch  20 |   100/  378 batches | accuracy    0.563\n",
            "| epoch  20 |   200/  378 batches | accuracy    0.579\n",
            "| epoch  20 |   300/  378 batches | accuracy    0.583\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  20 | time:  1.97s | test accuracy    0.538 \n",
            "-----------------------------------------------------------\n",
            "| epoch  21 |   100/  378 batches | accuracy    0.572\n",
            "| epoch  21 |   200/  378 batches | accuracy    0.578\n",
            "| epoch  21 |   300/  378 batches | accuracy    0.575\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  21 | time:  2.03s | test accuracy    0.538 \n",
            "-----------------------------------------------------------\n",
            "| epoch  22 |   100/  378 batches | accuracy    0.574\n",
            "| epoch  22 |   200/  378 batches | accuracy    0.580\n",
            "| epoch  22 |   300/  378 batches | accuracy    0.570\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  22 | time:  2.07s | test accuracy    0.538 \n",
            "-----------------------------------------------------------\n",
            "| epoch  23 |   100/  378 batches | accuracy    0.571\n",
            "| epoch  23 |   200/  378 batches | accuracy    0.578\n",
            "| epoch  23 |   300/  378 batches | accuracy    0.571\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  23 | time:  2.00s | test accuracy    0.538 \n",
            "-----------------------------------------------------------\n",
            "| epoch  24 |   100/  378 batches | accuracy    0.566\n",
            "| epoch  24 |   200/  378 batches | accuracy    0.574\n",
            "| epoch  24 |   300/  378 batches | accuracy    0.576\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  24 | time:  1.87s | test accuracy    0.538 \n",
            "-----------------------------------------------------------\n",
            "| epoch  25 |   100/  378 batches | accuracy    0.584\n",
            "| epoch  25 |   200/  378 batches | accuracy    0.569\n",
            "| epoch  25 |   300/  378 batches | accuracy    0.575\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  25 | time:  2.00s | test accuracy    0.538 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the Model on Input Text"
      ],
      "metadata": {
        "id": "chccJbgAl49E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_label = {2:\"Positive\", 1: \"Negative\", 0: \"Neutral\"}\n",
        "\n",
        "def predict(text, text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() "
      ],
      "metadata": {
        "id": "Z5qYVJrSl4h1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inp_text = \"Soooooo wish I could, but im in school and myspace is completely blocked\"\n",
        "# inp_text = \"The product is not good\"\n",
        "inp_text = \"It's super fun\"\n",
        "\n",
        "print(f\"This is a {sentiment_label[predict(inp_text, TEXT_PIPELINE)]} tweet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEkkWcVBmdWs",
        "outputId": "d567ec59-1e52-4b6d-d3c8-3bccdd230775"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a Positive tweet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References"
      ],
      "metadata": {
        "id": "4Sym3IOoifDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/rsreetech/PyTorchTextClassificationCustomDataset/blob/main/PyTorchTweetTextClassification.ipynb"
      ],
      "metadata": {
        "id": "tiVI6aPu_G9y"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}